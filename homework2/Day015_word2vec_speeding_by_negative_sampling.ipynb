{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5Pf_RxOIAYv"
   },
   "source": [
    "### 作業目的: 透過實作加速版word2vec Skip-gram模型來更加了解高速版的word2vec\n",
    "\n",
    "本次作業會採用Penn Tree Bank資料及，學員可以在ptb.train.txt中取得訓練文本資料。這次作業可以讓學員練習到以pytorch搭建模型與進行文本資料的前處理\n",
    "\n",
    "PS: 建議學員使用Colab (或可以使用GPU加速的機器)來進行作業，不然訓練會訓練到天荒地老....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO-a6e2OI5zg"
   },
   "source": [
    "### Connect to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 21059,
     "status": "ok",
     "timestamp": 1623975483234,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "LXPU7BI3HNJ6"
   },
   "outputs": [],
   "source": [
    "# # Import libraries for importing files from Google drive to Colab\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# # Authorize Google SDK to access Google Drive from Colab\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64517,
     "status": "ok",
     "timestamp": 1623980519406,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "K6dAH78QxVyD",
    "outputId": "d2943ced-5463-4b12-a0ae-a8a89a463985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2E7yb-qI9Uv"
   },
   "outputs": [],
   "source": [
    "#download = drive.CreateFile({'id': '1rNxkeWipGk8BnTvI17SCmq1Z4UcrPxYf'})\n",
    "#download.GetContentFile('ptb.train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKKpFV6GJwhs"
   },
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 3687,
     "status": "ok",
     "timestamp": 1623980628687,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "Yjz-fWmbJRPB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import urllib.request\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1137,
     "status": "ok",
     "timestamp": 1623980632486,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "i9xrgPu3KBgJ",
    "outputId": "ea6bebd0-440b-4435-e71d-9fdcba4f0e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 42068 lines\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料\n",
    "\n",
    "# Penn Tree Back dataset\n",
    "with open(\"./gdrive/My Drive/Colab Notebooks/ptb.train.txt\", encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"Total {len(lines)} lines\")\n",
    "raw_dataset = [line.split() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1623980635236,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "oAcF_5CQKH_J",
    "outputId": "b0972896-14d9-47dd-9c7e-ab86e9ca4bc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aer',\n",
       "  'banknote',\n",
       "  'berlitz',\n",
       "  'calloway',\n",
       "  'centrust',\n",
       "  'cluett',\n",
       "  'fromstein',\n",
       "  'gitano',\n",
       "  'guterman',\n",
       "  'hydro-quebec',\n",
       "  'ipo',\n",
       "  'kia',\n",
       "  'memotec',\n",
       "  'mlx',\n",
       "  'nahb',\n",
       "  'punts',\n",
       "  'rake',\n",
       "  'regatta',\n",
       "  'rubens',\n",
       "  'sim',\n",
       "  'snack-food',\n",
       "  'ssangyong',\n",
       "  'swapo',\n",
       "  'wachter'],\n",
       " ['pierre',\n",
       "  '<unk>',\n",
       "  'N',\n",
       "  'years',\n",
       "  'old',\n",
       "  'will',\n",
       "  'join',\n",
       "  'the',\n",
       "  'board',\n",
       "  'as',\n",
       "  'a',\n",
       "  'nonexecutive',\n",
       "  'director',\n",
       "  'nov.',\n",
       "  'N'],\n",
       " ['mr.',\n",
       "  '<unk>',\n",
       "  'is',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  '<unk>',\n",
       "  'n.v.',\n",
       "  'the',\n",
       "  'dutch',\n",
       "  'publishing',\n",
       "  'group'],\n",
       " ['rudolph',\n",
       "  '<unk>',\n",
       "  'N',\n",
       "  'years',\n",
       "  'old',\n",
       "  'and',\n",
       "  'former',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  'consolidated',\n",
       "  'gold',\n",
       "  'fields',\n",
       "  'plc',\n",
       "  'was',\n",
       "  'named',\n",
       "  'a',\n",
       "  'nonexecutive',\n",
       "  'director',\n",
       "  'of',\n",
       "  'this',\n",
       "  'british',\n",
       "  'industrial',\n",
       "  'conglomerate'],\n",
       " ['a',\n",
       "  'form',\n",
       "  'of',\n",
       "  'asbestos',\n",
       "  'once',\n",
       "  'used',\n",
       "  'to',\n",
       "  'make',\n",
       "  'kent',\n",
       "  'cigarette',\n",
       "  'filters',\n",
       "  'has',\n",
       "  'caused',\n",
       "  'a',\n",
       "  'high',\n",
       "  'percentage',\n",
       "  'of',\n",
       "  'cancer',\n",
       "  'deaths',\n",
       "  'among',\n",
       "  'a',\n",
       "  'group',\n",
       "  'of',\n",
       "  'workers',\n",
       "  'exposed',\n",
       "  'to',\n",
       "  'it',\n",
       "  'more',\n",
       "  'than',\n",
       "  'N',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'researchers',\n",
       "  'reported']]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看前5筆\n",
    "raw_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2649,
     "status": "ok",
     "timestamp": 1623980642515,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "3oki6AxhJyj4",
    "outputId": "d2051ff3-f715-45eb-84f5-0d6ad0406406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before subsampling: 876414 words\n",
      "After subsampling: 428971 words\n"
     ]
    }
   ],
   "source": [
    "# 定義資料前處理函示\n",
    "class PreProcessor():\n",
    "    '''Function to do preprocess of input corpus\n",
    "    Parameters\n",
    "    -----------\n",
    "    corpus: str\n",
    "        input corpus to be processed\n",
    "    only_word: bool\n",
    "        whether to filter out non-word\n",
    "    min_freq: int\n",
    "        minimum frequency of a word to be kept\n",
    "    do_subsampling: bool\n",
    "        whether to do subsampling\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, only_word: bool=False, min_freq: int=5, do_subsampling: bool=True, t: float=1e-5):\n",
    "        self.only_word = only_word\n",
    "        self.min_freq = min_freq\n",
    "        self.do_subsampling = do_subsampling\n",
    "        self.t = t\n",
    "    \n",
    "    def process(self, corpus: List[str]):\n",
    "        \n",
    "        word_dic = set()\n",
    "        counter = Counter()\n",
    "        processed_sentence = []\n",
    "        \n",
    "        for sentence in corpus:\n",
    "            # hint: 請計算字詞頻率\n",
    "            sentence = [word.lower() for word in sentence]\n",
    "            new_sentence = []\n",
    "            \n",
    "            \n",
    "            if self.only_word:\n",
    "                pattern = r'[a-z]+'\n",
    "                for word in sentence:\n",
    "                    m = re.search(pattern, word)\n",
    "                    if m is not None:\n",
    "                        new_sentence.append(m.group())\n",
    "            else:\n",
    "                pattern_withpunctuation = r'[a-z.,!?]'\n",
    "                for word in sentence:\n",
    "                    m = re.search(pattern_withpunctuation, word)\n",
    "                    if m is not None:\n",
    "                        new_sentence.append(m.group())\n",
    "            \n",
    "            \n",
    "            counter.update(new_sentence)\n",
    "            processed_sentence.append(new_sentence)\n",
    "                \n",
    "    \n",
    "        # hint: 移除頻率過小的字詞 建立word2idx與idx2word與word_frequency辭典\n",
    "        word_cnt = dict(filter(lambda x:x[1]>self.min_freq, counter.items()))\n",
    "        self.word2idx = {word:idx for idx, word in enumerate(word_cnt, 0)}\n",
    "        self.idx2word = {idx:word for word, idx in self.word2idx.items()}\n",
    "        self.word_frequency = word_cnt.copy()\n",
    "        \n",
    "        #將文本轉為ID型式與移除文本中頻率過小的文字\n",
    "        self.processed_corpus = [[self.word2idx[word] for word in sentence if word in self.word2idx] for sentence in processed_sentence]\n",
    "        self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
    "        print(f\"Before subsampling: {self.total_num_words} words\")\n",
    "        \n",
    "        # 進行二次採樣(subsampling)\n",
    "        if self.do_subsampling:\n",
    "            self.processed_corpus = [[idx for idx in sentence if self.subsampling(idx)]for sentence in self.processed_corpus]\n",
    "            self.total_num_words = sum([len(sentence) for sentence in self.processed_corpus])\n",
    "            print(f\"After subsampling: {self.total_num_words} words\")\n",
    "            counter = Counter([self.idx2word[idx] for sentence in self.processed_corpus for idx in sentence])\n",
    "            word_cnt = dict(counter.items())\n",
    "            self.word_frequency = word_cnt.copy()\n",
    "        \n",
    "        # hint: 移除空句子\n",
    "        self.processed_corpus = [[idx for idx in sentence] for sentence in self.processed_corpus if len(sentence)!=0 ]\n",
    "        \n",
    "        return self.processed_corpus, self.word2idx, self.idx2word, self.word_frequency, self.total_num_words\n",
    "    \n",
    "    def subsampling(self, idx):\n",
    "        \n",
    "        # hint: 學員可以參考講義的subsampling公式(也可自己定義一個)\n",
    "        \n",
    "        p = self.t / self.word_frequency[self.idx2word[idx]] *self.total_num_words\n",
    "        p_w = math.sqrt(p) + p\n",
    "        return random.uniform(0, 1) < p_w\n",
    "\n",
    "\n",
    "# 進行資料前處理\n",
    "# 這邊我們subsampling的t取1e-4\n",
    "pre_processor = PreProcessor(True, 5, True, 1e-4)\n",
    "corpus, word2idx, idx2word, word2freq, total_num_words = pre_processor.process(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfDuJuT5Kkvl"
   },
   "source": [
    "### 定義Skip-gram使用的Dataset與collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1623980656633,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "DraniEYMKfWl"
   },
   "outputs": [],
   "source": [
    "# 客製化Dataset\n",
    "class SkipGramGetAllDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, corpus, word2freq, word2idx, idx2word, window_size, num_negatives):\n",
    "        self.corpus = corpus\n",
    "        self.word2freq = word2freq\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.window_size = window_size\n",
    "        self.num_negatives = num_negatives\n",
    "        \n",
    "        self.all_targets, self.all_contexts = self._get_all_contexts_targets()\n",
    "        self.all_negatives = self._get_all_negatives()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # hint: 這裡我們會返回 目標字詞，上下文，負採樣樣本\n",
    "        return (self.all_targets[idx], self.all_contexts[idx], self.all_negatives[idx])\n",
    "        \n",
    "    \n",
    "    def _get_all_contexts_targets(self):\n",
    "        all_targets = []       # 上下文目標\n",
    "        all_contexts = []      # 文本的一個輸入單字\n",
    "        \n",
    "        for line in self.corpus:\n",
    "            if len(line) < 2*self.window_size + 1:\n",
    "                continue\n",
    "            \n",
    "            # hint: 這邊我們要創建文本的輸入單字 (考慮window_size)\n",
    "            for idx in line[self.window_size:-self.window_size]:\n",
    "                all_contexts.append([idx])\n",
    "            \n",
    "            for index in range(self.window_size, len(line) - self.window_size):\n",
    "                # hint: 創建目標上下文字詞\n",
    "                indices = list(range(index-self.window_size, index+self.window_size+1))\n",
    "                indices.remove(index)\n",
    "                all_targets.append([line[i] for i in indices])\n",
    "                               \n",
    "        return all_targets, all_contexts\n",
    "                               \n",
    "    \n",
    "    def _get_all_negatives(self):\n",
    "        \n",
    "        # hint: 進行負採樣，若沒頭緒的學員可以參考實作範例\n",
    "        target2freq = dict()\n",
    "        for target in self.all_targets:\n",
    "            target = tuple(target)\n",
    "            target2freq[target] = target2freq.get(target, 0) + 1\n",
    "        \n",
    "        cur_exists_target = list(target2freq.keys())\n",
    "        sampling_weights = [freq**0.75 for target, freq in target2freq.items()]\n",
    "        population = list(range(len(sampling_weights)))\n",
    "        \n",
    "        all_negatives = []\n",
    "        neg_candidate = []\n",
    "        i = 0\n",
    "        for j, target in enumerate(self.all_targets):\n",
    "            negatives = []\n",
    "            while len(negatives) < self.num_negatives:\n",
    "                if i == len(neg_candidate):\n",
    "                    neg_candidate = random.choices(population, sampling_weights, k=len(cur_exists_target))\n",
    "                    neg_candidate = list(map(lambda x: cur_exists_target[x], neg_candidate))\n",
    "                    i = 0\n",
    "                if neg_candidate[i] != tuple(target):\n",
    "                    negatives.append(list(neg_candidate[i]))\n",
    "                i+=1\n",
    "            all_negatives.append(negatives)\n",
    "        \n",
    "        return all_negatives\n",
    "    \n",
    "# 客製化collate_fn\n",
    "def skipgram_collate(data):\n",
    "    contexts = []\n",
    "    target_negative = []\n",
    "    labels = []\n",
    "    for target, context, negative in data:\n",
    "        # hint: 將目標字詞、上下文與負採樣樣本個別打包\n",
    "        target_negative.append([target]+negative)\n",
    "        labels.append([1]+[0]*len(negative))\n",
    "        contexts.append(context)\n",
    "    \n",
    "    return torch.tensor(contexts), torch.tensor(target_negative), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5172,
     "status": "ok",
     "timestamp": 1623980665964,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "3XXjD6tyeXeg",
    "outputId": "a3a4255e-3fe2-420e-d81a-7dc4051ee6ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[182],\n",
       "         [235]]), tensor([[[1973, 2114],\n",
       "          [7533, 1735],\n",
       "          [4245, 2456],\n",
       "          [8739, 2137]],\n",
       " \n",
       "         [[1036, 7805],\n",
       "          [ 105, 4116],\n",
       "          [6562, 1059],\n",
       "          [  16, 5456]]]), tensor([[1, 0, 0, 0],\n",
       "         [1, 0, 0, 0]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看資料產出\n",
    "d_set = SkipGramGetAllDataset(corpus, word2freq, word2idx, idx2word, window_size=1, num_negatives=3)\n",
    "dataloader = DataLoader(d_set, batch_size=2, shuffle=True, collate_fn=skipgram_collate)\n",
    "\n",
    "#透過next與iter取出資料\n",
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s94kJ0lKKzG5"
   },
   "source": [
    "### 定義Skip-gram模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1623980673752,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "kyyQyLxcKpv1"
   },
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super(SkipGram, self).__init__()\n",
    "        \n",
    "        self.in_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.out_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "    def forward(self, contexts, targets):\n",
    "        v = self.in_embedding(contexts)\n",
    "        u = torch.mean(self.out_embedding(targets), dim=2)\n",
    "        \n",
    "#         print(v.shape)\n",
    "#         print(u.shape)\n",
    "        # do dot product to get output\n",
    "        pred = torch.matmul(v, u.permute(0,2,1))\n",
    "        \n",
    "        return pred.squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHZIFz7yK5An"
   },
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1623980678598,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "AvEbGdsJeXej",
    "outputId": "3e02a961-c021-452e-fcbf-4ebd67f721ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 16150,
     "status": "ok",
     "timestamp": 1623980696577,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "Hr4sVBd8K10T"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "verbose = True\n",
    "num_epochs = 100\n",
    "batch_size = 512\n",
    "embed_size = 100\n",
    "lr = 0.01\n",
    "\n",
    "model = SkipGram(len(word2idx), embed_size)\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr) #學員可以自行選用optimizer\n",
    "dataset = SkipGramGetAllDataset(corpus, word2freq, word2idx, idx2word, window_size=2, num_negatives=5)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=skipgram_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5f605b7e37894952801b91c76e6ddfd3",
      "da98953f06604c5f952606e3f6c9313a",
      "325da7d91d424c808de244d73d9f7215",
      "f0cd532ad0c14be0b6629e82cd096190",
      "dd3aefa2ade840f58c1de8f1bd3f60de",
      "e4b86b1e4c8644bca6750a73b8625e5e",
      "981d7c525f2e48edad15981b4f20aa30",
      "0b0507fb76ce45b382481b8fdebc2ef8"
     ]
    },
    "executionInfo": {
     "elapsed": 248482,
     "status": "ok",
     "timestamp": 1623980963380,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "LV0CR95PeXek",
    "outputId": "6d0c2b42-2244-4df3-a8c8-e3960fb6d3d2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f605b7e37894952801b91c76e6ddfd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 1.41337\n",
      "Epoch: 2/100, Loss: 0.54139\n",
      "Epoch: 3/100, Loss: 0.34487\n",
      "Epoch: 4/100, Loss: 0.25823\n",
      "Epoch: 5/100, Loss: 0.20667\n",
      "Epoch: 6/100, Loss: 0.16951\n",
      "Epoch: 7/100, Loss: 0.13999\n",
      "Epoch: 8/100, Loss: 0.11562\n",
      "Epoch: 9/100, Loss: 0.09520\n",
      "Epoch: 10/100, Loss: 0.07814\n",
      "Epoch: 11/100, Loss: 0.06392\n",
      "Epoch: 12/100, Loss: 0.05244\n",
      "Epoch: 13/100, Loss: 0.04290\n",
      "Epoch: 14/100, Loss: 0.03529\n",
      "Epoch: 15/100, Loss: 0.02920\n",
      "Epoch: 16/100, Loss: 0.02451\n",
      "Epoch: 17/100, Loss: 0.02088\n",
      "Epoch: 18/100, Loss: 0.01815\n",
      "Epoch: 19/100, Loss: 0.01612\n",
      "Epoch: 20/100, Loss: 0.01469\n",
      "Epoch: 21/100, Loss: 0.01340\n",
      "Epoch: 22/100, Loss: 0.01252\n",
      "Epoch: 23/100, Loss: 0.01181\n",
      "Epoch: 24/100, Loss: 0.01129\n",
      "Epoch: 25/100, Loss: 0.01102\n",
      "Epoch: 26/100, Loss: 0.01057\n",
      "Epoch: 27/100, Loss: 0.01061\n",
      "Epoch: 28/100, Loss: 0.01020\n",
      "Epoch: 29/100, Loss: 0.00977\n",
      "Epoch: 30/100, Loss: 0.00923\n",
      "Epoch: 31/100, Loss: 0.00892\n",
      "Epoch: 32/100, Loss: 0.00854\n",
      "Epoch: 33/100, Loss: 0.00856\n",
      "Epoch: 34/100, Loss: 0.00815\n",
      "Epoch: 35/100, Loss: 0.00843\n",
      "Epoch: 36/100, Loss: 0.00835\n",
      "Epoch: 37/100, Loss: 0.00896\n",
      "Epoch: 38/100, Loss: 0.00961\n",
      "Epoch: 39/100, Loss: 0.01026\n",
      "Epoch: 40/100, Loss: 0.00927\n",
      "Epoch: 41/100, Loss: 0.00778\n",
      "Epoch: 42/100, Loss: 0.00699\n",
      "Epoch: 43/100, Loss: 0.00697\n",
      "Epoch: 44/100, Loss: 0.00697\n",
      "Epoch: 45/100, Loss: 0.00713\n",
      "Epoch: 46/100, Loss: 0.00725\n",
      "Epoch: 47/100, Loss: 0.00711\n",
      "Epoch: 48/100, Loss: 0.00754\n",
      "Epoch: 49/100, Loss: 0.00791\n",
      "Epoch: 50/100, Loss: 0.00951\n",
      "Epoch: 51/100, Loss: 0.01234\n",
      "Epoch: 52/100, Loss: 0.01057\n",
      "Epoch: 53/100, Loss: 0.00719\n",
      "Epoch: 54/100, Loss: 0.00608\n",
      "Epoch: 55/100, Loss: 0.00592\n",
      "Epoch: 56/100, Loss: 0.00625\n",
      "Epoch: 57/100, Loss: 0.00632\n",
      "Epoch: 58/100, Loss: 0.00657\n",
      "Epoch: 59/100, Loss: 0.00662\n",
      "Epoch: 60/100, Loss: 0.00667\n",
      "Epoch: 61/100, Loss: 0.00672\n",
      "Epoch: 62/100, Loss: 0.00710\n",
      "Epoch: 63/100, Loss: 0.00827\n",
      "Epoch: 64/100, Loss: 0.01212\n",
      "Epoch: 65/100, Loss: 0.01123\n",
      "Epoch: 66/100, Loss: 0.00744\n",
      "Epoch: 67/100, Loss: 0.00586\n",
      "Epoch: 68/100, Loss: 0.00544\n",
      "Epoch: 69/100, Loss: 0.00573\n",
      "Epoch: 70/100, Loss: 0.00584\n",
      "Epoch: 71/100, Loss: 0.00601\n",
      "Epoch: 72/100, Loss: 0.00614\n",
      "Epoch: 73/100, Loss: 0.00609\n",
      "Epoch: 74/100, Loss: 0.00641\n",
      "Epoch: 75/100, Loss: 0.00642\n",
      "Epoch: 76/100, Loss: 0.00673\n",
      "Epoch: 77/100, Loss: 0.00887\n",
      "Epoch: 78/100, Loss: 0.01312\n",
      "Epoch: 79/100, Loss: 0.00977\n",
      "Epoch: 80/100, Loss: 0.00646\n",
      "Epoch: 81/100, Loss: 0.00532\n",
      "Epoch: 82/100, Loss: 0.00525\n",
      "Epoch: 83/100, Loss: 0.00543\n",
      "Epoch: 84/100, Loss: 0.00576\n",
      "Epoch: 85/100, Loss: 0.00579\n",
      "Epoch: 86/100, Loss: 0.00570\n",
      "Epoch: 87/100, Loss: 0.00601\n",
      "Epoch: 88/100, Loss: 0.00600\n",
      "Epoch: 89/100, Loss: 0.00633\n",
      "Epoch: 90/100, Loss: 0.00731\n",
      "Epoch: 91/100, Loss: 0.01035\n",
      "Epoch: 92/100, Loss: 0.01144\n",
      "Epoch: 93/100, Loss: 0.00771\n",
      "Epoch: 94/100, Loss: 0.00536\n",
      "Epoch: 95/100, Loss: 0.00504\n",
      "Epoch: 96/100, Loss: 0.00509\n",
      "Epoch: 97/100, Loss: 0.00541\n",
      "Epoch: 98/100, Loss: 0.00524\n",
      "Epoch: 99/100, Loss: 0.00547\n",
      "Epoch: 100/100, Loss: 0.00571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "\n",
    "lst_loss = []\n",
    "model.train()\n",
    "for epc in tqdm(range(num_epochs)):\n",
    "    batch_loss = 0\n",
    "\n",
    "    for i, (contexts, target_negative, labels) in enumerate(loader, 1):\n",
    "        # hint: 開始訓練前要先將optimizer的梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_cuda:\n",
    "            contexts = contexts.cuda()\n",
    "            target_negative = target_negative.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        pred = model(contexts, target_negative)\n",
    "        loss = criterion(pred.float(), labels.float())\n",
    "        batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         if i % 500 == 0:\n",
    "#             print(f\"Epoch: {epc + 1}/{num_epochs}, Batch: {i+1}/{len(dataset)/batch_size} Loss: {batch_loss / i:.5f}\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Epoch: {epc + 1}/{num_epochs}, Loss: {batch_loss / i:.5f}\")\n",
    "    \n",
    "    lst_loss.append(batch_loss/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219482,
     "status": "ok",
     "timestamp": 1606321001876,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "sE28LW2_LB0I",
    "outputId": "4cf7c434-b5b8-4e73-eb3c-c2735ef0d17c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Batch: 501/715.900390625 Loss: 1.05744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:02<03:51,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 0.92186\n",
      "Epoch: 2/100, Batch: 501/715.900390625 Loss: 0.55346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [00:04<03:43,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100, Loss: 0.55015\n",
      "Epoch: 3/100, Batch: 501/715.900390625 Loss: 0.52754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [00:06<03:39,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100, Loss: 0.52725\n",
      "Epoch: 4/100, Batch: 501/715.900390625 Loss: 0.51811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:08<03:33,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100, Loss: 0.51852\n",
      "Epoch: 5/100, Batch: 501/715.900390625 Loss: 0.51259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [00:11<03:34,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100, Loss: 0.51321\n",
      "Epoch: 6/100, Batch: 501/715.900390625 Loss: 0.50900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [00:13<03:33,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100, Loss: 0.50949\n",
      "Epoch: 7/100, Batch: 501/715.900390625 Loss: 0.50621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [00:15<03:26,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100, Loss: 0.50693\n",
      "Epoch: 8/100, Batch: 501/715.900390625 Loss: 0.50430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [00:17<03:20,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100, Loss: 0.50504\n",
      "Epoch: 9/100, Batch: 501/715.900390625 Loss: 0.50258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:19<03:21,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100, Loss: 0.50363\n",
      "Epoch: 10/100, Batch: 501/715.900390625 Loss: 0.50150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [00:22<03:15,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100, Loss: 0.50275\n",
      "Epoch: 11/100, Batch: 501/715.900390625 Loss: 0.50085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [00:24<03:12,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100, Loss: 0.50200\n",
      "Epoch: 12/100, Batch: 501/715.900390625 Loss: 0.50052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [00:26<03:12,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100, Loss: 0.50164\n",
      "Epoch: 13/100, Batch: 501/715.900390625 Loss: 0.50018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [00:28<03:08,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100, Loss: 0.50131\n",
      "Epoch: 14/100, Batch: 501/715.900390625 Loss: 0.50011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [00:30<03:04,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100, Loss: 0.50111\n",
      "Epoch: 15/100, Batch: 501/715.900390625 Loss: 0.49991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [00:32<03:07,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100, Loss: 0.50087\n",
      "Epoch: 16/100, Batch: 501/715.900390625 Loss: 0.49975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [00:35<03:02,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100, Loss: 0.50065\n",
      "Epoch: 17/100, Batch: 501/715.900390625 Loss: 0.49984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [00:37<02:57,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100, Loss: 0.50059\n",
      "Epoch: 18/100, Batch: 501/715.900390625 Loss: 0.49951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [00:39<02:58,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100, Loss: 0.50043\n",
      "Epoch: 19/100, Batch: 501/715.900390625 Loss: 0.49927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [00:41<02:54,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100, Loss: 0.50029\n",
      "Epoch: 20/100, Batch: 501/715.900390625 Loss: 0.49868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [00:43<02:50,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100, Loss: 0.50012\n",
      "Epoch: 21/100, Batch: 501/715.900390625 Loss: 0.49861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [00:45<02:52,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100, Loss: 0.50000\n",
      "Epoch: 22/100, Batch: 501/715.900390625 Loss: 0.49861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [00:47<02:47,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100, Loss: 0.49999\n",
      "Epoch: 23/100, Batch: 501/715.900390625 Loss: 0.49870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [00:50<02:47,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100, Loss: 0.49994\n",
      "Epoch: 24/100, Batch: 501/715.900390625 Loss: 0.49904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [00:52<02:42,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100, Loss: 0.49985\n",
      "Epoch: 25/100, Batch: 501/715.900390625 Loss: 0.49885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [00:54<02:43,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100, Loss: 0.49992\n",
      "Epoch: 26/100, Batch: 501/715.900390625 Loss: 0.49906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [00:56<02:38,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100, Loss: 0.49983\n",
      "Epoch: 27/100, Batch: 501/715.900390625 Loss: 0.49881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [00:58<02:37,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100, Loss: 0.49972\n",
      "Epoch: 28/100, Batch: 501/715.900390625 Loss: 0.49846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [01:01<02:38,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100, Loss: 0.49966\n",
      "Epoch: 29/100, Batch: 501/715.900390625 Loss: 0.49889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [01:03<02:35,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100, Loss: 0.49968\n",
      "Epoch: 30/100, Batch: 501/715.900390625 Loss: 0.49847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [01:05<02:32,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100, Loss: 0.49968\n",
      "Epoch: 31/100, Batch: 501/715.900390625 Loss: 0.49857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [01:07<02:33,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100, Loss: 0.49964\n",
      "Epoch: 32/100, Batch: 501/715.900390625 Loss: 0.49833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [01:09<02:29,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100, Loss: 0.49959\n",
      "Epoch: 33/100, Batch: 501/715.900390625 Loss: 0.49836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [01:12<02:26,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100, Loss: 0.49948\n",
      "Epoch: 34/100, Batch: 501/715.900390625 Loss: 0.49889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [01:14<02:28,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100, Loss: 0.49949\n",
      "Epoch: 35/100, Batch: 501/715.900390625 Loss: 0.49865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [01:16<02:23,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100, Loss: 0.49945\n",
      "Epoch: 36/100, Batch: 501/715.900390625 Loss: 0.49856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [01:18<02:19,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100, Loss: 0.49947\n",
      "Epoch: 37/100, Batch: 501/715.900390625 Loss: 0.49827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [01:20<02:20,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100, Loss: 0.49938\n",
      "Epoch: 38/100, Batch: 501/715.900390625 Loss: 0.49820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [01:23<02:15,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100, Loss: 0.49939\n",
      "Epoch: 39/100, Batch: 501/715.900390625 Loss: 0.49815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [01:25<02:12,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100, Loss: 0.49942\n",
      "Epoch: 40/100, Batch: 501/715.900390625 Loss: 0.49845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [01:27<02:12,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100, Loss: 0.49938\n",
      "Epoch: 41/100, Batch: 501/715.900390625 Loss: 0.49821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [01:29<02:07,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100, Loss: 0.49929\n",
      "Epoch: 42/100, Batch: 501/715.900390625 Loss: 0.49841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [01:31<02:06,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100, Loss: 0.49931\n",
      "Epoch: 43/100, Batch: 501/715.900390625 Loss: 0.49820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [01:33<02:04,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100, Loss: 0.49922\n",
      "Epoch: 44/100, Batch: 501/715.900390625 Loss: 0.49812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [01:36<02:04,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100, Loss: 0.49929\n",
      "Epoch: 45/100, Batch: 501/715.900390625 Loss: 0.49817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [01:38<02:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100, Loss: 0.49923\n",
      "Epoch: 46/100, Batch: 501/715.900390625 Loss: 0.49808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [01:40<01:56,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100, Loss: 0.49923\n",
      "Epoch: 47/100, Batch: 501/715.900390625 Loss: 0.49797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [01:42<01:55,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100, Loss: 0.49931\n",
      "Epoch: 48/100, Batch: 501/715.900390625 Loss: 0.49821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [01:44<01:52,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100, Loss: 0.49915\n",
      "Epoch: 49/100, Batch: 501/715.900390625 Loss: 0.49843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [01:46<01:48,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100, Loss: 0.49922\n",
      "Epoch: 50/100, Batch: 501/715.900390625 Loss: 0.49797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [01:49<01:48,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100, Loss: 0.49914\n",
      "Epoch: 51/100, Batch: 501/715.900390625 Loss: 0.49800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [01:51<01:44,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100, Loss: 0.49923\n",
      "Epoch: 52/100, Batch: 501/715.900390625 Loss: 0.49794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 52/100 [01:53<01:42,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100, Loss: 0.49921\n",
      "Epoch: 53/100, Batch: 501/715.900390625 Loss: 0.49806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [01:55<01:42,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100, Loss: 0.49913\n",
      "Epoch: 54/100, Batch: 501/715.900390625 Loss: 0.49832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [01:57<01:38,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100, Loss: 0.49912\n",
      "Epoch: 55/100, Batch: 501/715.900390625 Loss: 0.49767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [01:59<01:35,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/100, Loss: 0.49916\n",
      "Epoch: 56/100, Batch: 501/715.900390625 Loss: 0.49798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [02:01<01:35,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100, Loss: 0.49902\n",
      "Epoch: 57/100, Batch: 501/715.900390625 Loss: 0.49789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [02:04<01:32,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100, Loss: 0.49909\n",
      "Epoch: 58/100, Batch: 501/715.900390625 Loss: 0.49810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [02:06<01:29,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100, Loss: 0.49908\n",
      "Epoch: 59/100, Batch: 501/715.900390625 Loss: 0.49815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [02:08<01:28,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100, Loss: 0.49912\n",
      "Epoch: 60/100, Batch: 501/715.900390625 Loss: 0.49804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [02:10<01:25,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100, Loss: 0.49910\n",
      "Epoch: 61/100, Batch: 501/715.900390625 Loss: 0.49820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [02:12<01:22,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100, Loss: 0.49907\n",
      "Epoch: 62/100, Batch: 501/715.900390625 Loss: 0.49785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [02:14<01:22,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100, Loss: 0.49905\n",
      "Epoch: 63/100, Batch: 501/715.900390625 Loss: 0.49801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [02:16<01:19,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100, Loss: 0.49910\n",
      "Epoch: 64/100, Batch: 501/715.900390625 Loss: 0.49799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [02:19<01:16,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100, Loss: 0.49903\n",
      "Epoch: 65/100, Batch: 501/715.900390625 Loss: 0.49827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [02:21<01:14,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100, Loss: 0.49902\n",
      "Epoch: 66/100, Batch: 501/715.900390625 Loss: 0.49774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [02:23<01:14,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100, Loss: 0.49899\n",
      "Epoch: 67/100, Batch: 501/715.900390625 Loss: 0.49813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [02:25<01:11,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100, Loss: 0.49904\n",
      "Epoch: 68/100, Batch: 501/715.900390625 Loss: 0.49812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [02:27<01:08,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100, Loss: 0.49906\n",
      "Epoch: 69/100, Batch: 501/715.900390625 Loss: 0.49797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [02:30<01:08,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100, Loss: 0.49901\n",
      "Epoch: 70/100, Batch: 501/715.900390625 Loss: 0.49804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 70/100 [02:32<01:06,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100, Loss: 0.49899\n",
      "Epoch: 71/100, Batch: 501/715.900390625 Loss: 0.49778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [02:34<01:04,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100, Loss: 0.49890\n",
      "Epoch: 72/100, Batch: 501/715.900390625 Loss: 0.49829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 72/100 [02:36<01:03,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100, Loss: 0.49907\n",
      "Epoch: 73/100, Batch: 501/715.900390625 Loss: 0.49815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [02:39<01:01,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100, Loss: 0.49894\n",
      "Epoch: 74/100, Batch: 501/715.900390625 Loss: 0.49768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [02:41<00:58,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100, Loss: 0.49893\n",
      "Epoch: 75/100, Batch: 501/715.900390625 Loss: 0.49777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [02:43<00:56,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100, Loss: 0.49896\n",
      "Epoch: 76/100, Batch: 501/715.900390625 Loss: 0.49793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [02:45<00:53,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100, Loss: 0.49893\n",
      "Epoch: 77/100, Batch: 501/715.900390625 Loss: 0.49772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [02:47<00:50,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100, Loss: 0.49894\n",
      "Epoch: 78/100, Batch: 501/715.900390625 Loss: 0.49782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 78/100 [02:50<00:49,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/100, Loss: 0.49886\n",
      "Epoch: 79/100, Batch: 501/715.900390625 Loss: 0.49785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [02:52<00:46,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100, Loss: 0.49894\n",
      "Epoch: 80/100, Batch: 501/715.900390625 Loss: 0.49772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [02:54<00:43,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100, Loss: 0.49890\n",
      "Epoch: 81/100, Batch: 501/715.900390625 Loss: 0.49803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [02:56<00:42,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100, Loss: 0.49899\n",
      "Epoch: 82/100, Batch: 501/715.900390625 Loss: 0.49771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 82/100 [02:59<00:39,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100, Loss: 0.49892\n",
      "Epoch: 83/100, Batch: 501/715.900390625 Loss: 0.49785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [03:01<00:37,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/100, Loss: 0.49898\n",
      "Epoch: 84/100, Batch: 501/715.900390625 Loss: 0.49766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [03:03<00:35,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100, Loss: 0.49889\n",
      "Epoch: 85/100, Batch: 501/715.900390625 Loss: 0.49806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [03:05<00:33,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100, Loss: 0.49894\n",
      "Epoch: 86/100, Batch: 501/715.900390625 Loss: 0.49808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [03:07<00:30,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100, Loss: 0.49894\n",
      "Epoch: 87/100, Batch: 501/715.900390625 Loss: 0.49790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [03:10<00:28,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100, Loss: 0.49890\n",
      "Epoch: 88/100, Batch: 501/715.900390625 Loss: 0.49794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 88/100 [03:12<00:26,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100, Loss: 0.49889\n",
      "Epoch: 89/100, Batch: 501/715.900390625 Loss: 0.49799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [03:14<00:24,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100, Loss: 0.49887\n",
      "Epoch: 90/100, Batch: 501/715.900390625 Loss: 0.49843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 90/100 [03:16<00:21,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100, Loss: 0.49897\n",
      "Epoch: 91/100, Batch: 501/715.900390625 Loss: 0.49803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [03:18<00:19,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100, Loss: 0.49893\n",
      "Epoch: 92/100, Batch: 501/715.900390625 Loss: 0.49793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [03:20<00:17,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100, Loss: 0.49884\n",
      "Epoch: 93/100, Batch: 501/715.900390625 Loss: 0.49789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [03:23<00:15,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100, Loss: 0.49892\n",
      "Epoch: 94/100, Batch: 501/715.900390625 Loss: 0.49790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [03:25<00:13,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100, Loss: 0.49883\n",
      "Epoch: 95/100, Batch: 501/715.900390625 Loss: 0.49787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [03:27<00:11,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100, Loss: 0.49895\n",
      "Epoch: 96/100, Batch: 501/715.900390625 Loss: 0.49816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [03:29<00:08,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100, Loss: 0.49890\n",
      "Epoch: 97/100, Batch: 501/715.900390625 Loss: 0.49785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [03:32<00:06,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100, Loss: 0.49891\n",
      "Epoch: 98/100, Batch: 501/715.900390625 Loss: 0.49778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [03:34<00:04,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100, Loss: 0.49884\n",
      "Epoch: 99/100, Batch: 501/715.900390625 Loss: 0.49746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [03:36<00:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100, Loss: 0.49891\n",
      "Epoch: 100/100, Batch: 501/715.900390625 Loss: 0.49763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:38<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100, Loss: 0.49883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "\n",
    "# lst_loss = []\n",
    "# model.train()\n",
    "# for epc in tqdm.tqdm(range(num_epochs)):\n",
    "#     batch_loss = 0\n",
    "\n",
    "#     for i, (contexts, target_negative, labels) in enumerate(loader, 1):\n",
    "#         # hint: 開始訓練前要先將optimizer的梯度歸零\n",
    "        \n",
    "#         ### <your code> ###\n",
    "        \n",
    "#         if use_cuda:\n",
    "#             ### <your code> ###\n",
    "        \n",
    "#         pred = ### <your code> ###\n",
    "#         loss = ### <your code> ###\n",
    "#         batch_loss += loss.item()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if i % 500 == 0:\n",
    "#             print(f\"Epoch: {epc + 1}/{num_epochs}, Batch: {i+1}/{len(dataset)/batch_size} Loss: {batch_loss / i:.5f}\")\n",
    "    \n",
    "#     if verbose:\n",
    "#         print(f\"Epoch: {epc + 1}/{num_epochs}, Loss: {batch_loss / i:.5f}\")\n",
    "    \n",
    "#     lst_loss.append(batch_loss/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1623981145041,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "y0rt5W2ELLvP",
    "outputId": "7a77cd16-a18d-484c-d8b2-f3233d333dea"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(lst_loss, marker='s')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Word2Vec Skip-gram Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1623981152831,
     "user": {
      "displayName": "Brian Lin",
      "photoUrl": "",
      "userId": "12010684563378800672"
     },
     "user_tz": -480
    },
    "id": "43pOYRh-MX_F",
    "outputId": "72e875d8-a586-4339-bf8b-989d1d148802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.394: mystery.\n",
      "cosine sim=0.370: cold.\n",
      "cosine sim=0.352: hate.\n",
      "cosine sim=0.349: authorities.\n"
     ]
    }
   ],
   "source": [
    "#計算字詞相似度\n",
    "\n",
    "def get_similarity(word, top_k, model, word2idx, idx2word):\n",
    "    W = (model.in_embedding.weight.data + model.out_embedding.weight.data) / 2\n",
    "    idx = word2idx.get(word, None)\n",
    "    \n",
    "    if not idx:\n",
    "        # 當出現不在字典中的字詞時，顯示Out of vocabulary error\n",
    "        raise ValueError(\"Out of vocabulary\")\n",
    "    else:\n",
    "        x = W[idx]\n",
    "        \n",
    "        # 使用cosine相似計算字詞間的相似程度\n",
    "        cos = torch.matmul(W, x) / (torch.sum(W * W, dim=-1) * torch.sum(x * x) + 1e-9).sqrt()\n",
    "        _, topk = torch.topk(cos, top_k+1)\n",
    "        \n",
    "        for i in topk[1:]:\n",
    "            print(f\"cosine sim={cos[int(i)]:.3f}: {idx2word[int(i)]}.\")\n",
    "\n",
    "get_similarity('love', 4, model, word2idx, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_tL9g0oMcCT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "word2vec高速化_作業.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b0507fb76ce45b382481b8fdebc2ef8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "325da7d91d424c808de244d73d9f7215": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4b86b1e4c8644bca6750a73b8625e5e",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd3aefa2ade840f58c1de8f1bd3f60de",
      "value": 100
     }
    },
    "5f605b7e37894952801b91c76e6ddfd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_325da7d91d424c808de244d73d9f7215",
       "IPY_MODEL_f0cd532ad0c14be0b6629e82cd096190"
      ],
      "layout": "IPY_MODEL_da98953f06604c5f952606e3f6c9313a"
     }
    },
    "981d7c525f2e48edad15981b4f20aa30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da98953f06604c5f952606e3f6c9313a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd3aefa2ade840f58c1de8f1bd3f60de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e4b86b1e4c8644bca6750a73b8625e5e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0cd532ad0c14be0b6629e82cd096190": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b0507fb76ce45b382481b8fdebc2ef8",
      "placeholder": "​",
      "style": "IPY_MODEL_981d7c525f2e48edad15981b4f20aa30",
      "value": " 100/100 [04:08&lt;00:00,  2.48s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
