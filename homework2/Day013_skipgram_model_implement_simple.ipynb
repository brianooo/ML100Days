{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 實作word2vec Skip-gram模型\n",
    "在課程中了解如何搭建CBOW模型，這次的作業目的在於透過搭建Skip-gram模型來了解另外一種word2vec的架構。\n",
    "\n",
    "Hint_1: 學員可以善用課程中以搭建好的function模組\n",
    "Hint_2: Skip_gram所需的輸入資料與目標跟CBOW有些許不同，Skip_gram是由中間字詞預測上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils.utility import clip_grads, convert_one_hot, preprocess, Trainer\n",
    "from utils.layers import Dense, SoftmaxWithCrossEntropy\n",
    "from utils.optimizer import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6, 4, 0, 1, 5, 7, 3, 2]]),\n",
       " {'studying': 0,\n",
       "  'natural': 1,\n",
       "  '.': 2,\n",
       "  'now': 3,\n",
       "  'am': 4,\n",
       "  'language': 5,\n",
       "  'i': 6,\n",
       "  'processing': 7},\n",
       " {0: 'studying',\n",
       "  1: 'natural',\n",
       "  2: '.',\n",
       "  3: 'now',\n",
       "  4: 'am',\n",
       "  5: 'language',\n",
       "  6: 'i',\n",
       "  7: 'processing'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same corpus as in the lecture\n",
    "text = \"I am studying Natural Language Processing now.\"\n",
    "\n",
    "# transform corpus to contexts and targets pair\n",
    "corpus, word2idx, idx2word = preprocess([text])\n",
    "corpus, word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 0, 1, 5, 7, 3]),\n",
       " array([[6, 0],\n",
       "        [4, 1],\n",
       "        [0, 5],\n",
       "        [1, 7],\n",
       "        [5, 3],\n",
       "        [7, 2]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define create_contexts_target function\n",
    "def create_contexts_target(corpus: List, window_size: int=1):\n",
    "    \n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i, idx in enumerate(corpus[window_size:-window_size], start=window_size):\n",
    "        contexts.append(idx)\n",
    "        pre = list(corpus[i-window_size:i])\n",
    "        post = list(corpus[i+1:i+window_size+1])\n",
    "        targets.append(pre+post)\n",
    "\n",
    "    return np.array(contexts), np.array(targets)\n",
    "\n",
    "contexts, targets= create_contexts_target(corpus[0], window_size=1)\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0]]),\n",
       " array([[[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0]],\n",
       " \n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0]]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform contexts and targets to one-hot encoding\n",
    "contexts = convert_one_hot(contexts, len(word2idx))\n",
    "targets = convert_one_hot(targets, len(word2idx))\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Skip-gram model\n",
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # initialize weights\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # create layers\n",
    "        self.in_layer = Dense(W_in)\n",
    "        self.out_layer = Dense(W_out)\n",
    "        self.loss_layer = [SoftmaxWithCrossEntropy() for i in range(self.window_size*2)]\n",
    "        \n",
    "\n",
    "        layers = [self.in_layer, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        # word vector matrix\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, targets):\n",
    "        h = self.in_layer.forward(contexts)\n",
    "        s = self.out_layer.forward(h)\n",
    "        \n",
    "        loss = sum([self.loss_layer[i].forward(s, targets[:, i]) for i in range(self.window_size*2)])\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        \n",
    "        ds = sum([self.loss_layer[i].backward(dout) for i in range(self.window_size*2)]) \n",
    "        dh = self.out_layer.backward(ds)\n",
    "        self.in_layer.backward(dh)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▍                                                                    | 110/1000 [00:00<00:00, 1099.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 1/2, Loss: 4.158765248316547\n",
      "Epoch: 2, Iteration: 1/2, Loss: 4.158832344611928\n",
      "Epoch: 3, Iteration: 1/2, Loss: 4.158676004350825\n",
      "Epoch: 4, Iteration: 1/2, Loss: 4.1587360466939485\n",
      "Epoch: 5, Iteration: 1/2, Loss: 4.158583424880192\n",
      "Epoch: 6, Iteration: 1/2, Loss: 4.158660664714541\n",
      "Epoch: 7, Iteration: 1/2, Loss: 4.158504742460407\n",
      "Epoch: 8, Iteration: 1/2, Loss: 4.158472011718142\n",
      "Epoch: 9, Iteration: 1/2, Loss: 4.158543447666597\n",
      "Epoch: 10, Iteration: 1/2, Loss: 4.15838623435536\n",
      "Epoch: 11, Iteration: 1/2, Loss: 4.158324969606671\n",
      "Epoch: 12, Iteration: 1/2, Loss: 4.158265445306498\n",
      "Epoch: 13, Iteration: 1/2, Loss: 4.157975819526989\n",
      "Epoch: 14, Iteration: 1/2, Loss: 4.158097028658086\n",
      "Epoch: 15, Iteration: 1/2, Loss: 4.158074134107924\n",
      "Epoch: 16, Iteration: 1/2, Loss: 4.157883721273583\n",
      "Epoch: 17, Iteration: 1/2, Loss: 4.157744772643391\n",
      "Epoch: 18, Iteration: 1/2, Loss: 4.15797181027895\n",
      "Epoch: 19, Iteration: 1/2, Loss: 4.1576352370193455\n",
      "Epoch: 20, Iteration: 1/2, Loss: 4.157712814793124\n",
      "Epoch: 21, Iteration: 1/2, Loss: 4.1573748872427725\n",
      "Epoch: 22, Iteration: 1/2, Loss: 4.157185051648156\n",
      "Epoch: 23, Iteration: 1/2, Loss: 4.1569159085493546\n",
      "Epoch: 24, Iteration: 1/2, Loss: 4.157078045875543\n",
      "Epoch: 25, Iteration: 1/2, Loss: 4.156172707830006\n",
      "Epoch: 26, Iteration: 1/2, Loss: 4.156739146261575\n",
      "Epoch: 27, Iteration: 1/2, Loss: 4.1560940562529805\n",
      "Epoch: 28, Iteration: 1/2, Loss: 4.15601823244444\n",
      "Epoch: 29, Iteration: 1/2, Loss: 4.156554681020479\n",
      "Epoch: 30, Iteration: 1/2, Loss: 4.155630640346438\n",
      "Epoch: 31, Iteration: 1/2, Loss: 4.153725772755828\n",
      "Epoch: 32, Iteration: 1/2, Loss: 4.156081055605326\n",
      "Epoch: 33, Iteration: 1/2, Loss: 4.1530976045020465\n",
      "Epoch: 34, Iteration: 1/2, Loss: 4.153029142909835\n",
      "Epoch: 35, Iteration: 1/2, Loss: 4.15424891566706\n",
      "Epoch: 36, Iteration: 1/2, Loss: 4.152610779335969\n",
      "Epoch: 37, Iteration: 1/2, Loss: 4.151182980433465\n",
      "Epoch: 38, Iteration: 1/2, Loss: 4.152210379750034\n",
      "Epoch: 39, Iteration: 1/2, Loss: 4.15198345877223\n",
      "Epoch: 40, Iteration: 1/2, Loss: 4.151007230247467\n",
      "Epoch: 41, Iteration: 1/2, Loss: 4.1477229457139355\n",
      "Epoch: 42, Iteration: 1/2, Loss: 4.146021405679969\n",
      "Epoch: 43, Iteration: 1/2, Loss: 4.151878281061532\n",
      "Epoch: 44, Iteration: 1/2, Loss: 4.1452868270591035\n",
      "Epoch: 45, Iteration: 1/2, Loss: 4.140372888177406\n",
      "Epoch: 46, Iteration: 1/2, Loss: 4.148556536239421\n",
      "Epoch: 47, Iteration: 1/2, Loss: 4.140468552079671\n",
      "Epoch: 48, Iteration: 1/2, Loss: 4.136380248852161\n",
      "Epoch: 49, Iteration: 1/2, Loss: 4.142821346062869\n",
      "Epoch: 50, Iteration: 1/2, Loss: 4.138078038982142\n",
      "Epoch: 51, Iteration: 1/2, Loss: 4.134135615579799\n",
      "Epoch: 52, Iteration: 1/2, Loss: 4.1338245303219345\n",
      "Epoch: 53, Iteration: 1/2, Loss: 4.120209632925196\n",
      "Epoch: 54, Iteration: 1/2, Loss: 4.121171227849336\n",
      "Epoch: 55, Iteration: 1/2, Loss: 4.127462169003541\n",
      "Epoch: 56, Iteration: 1/2, Loss: 4.105840388645544\n",
      "Epoch: 57, Iteration: 1/2, Loss: 4.123079346960131\n",
      "Epoch: 58, Iteration: 1/2, Loss: 4.1074981832728925\n",
      "Epoch: 59, Iteration: 1/2, Loss: 4.11193904733922\n",
      "Epoch: 60, Iteration: 1/2, Loss: 4.096544256418048\n",
      "Epoch: 61, Iteration: 1/2, Loss: 4.108227549138422\n",
      "Epoch: 62, Iteration: 1/2, Loss: 4.061625901071237\n",
      "Epoch: 63, Iteration: 1/2, Loss: 4.102940042964916\n",
      "Epoch: 64, Iteration: 1/2, Loss: 4.052938011990976\n",
      "Epoch: 65, Iteration: 1/2, Loss: 4.032692192386633\n",
      "Epoch: 66, Iteration: 1/2, Loss: 4.060155904551728\n",
      "Epoch: 67, Iteration: 1/2, Loss: 4.046299651645064\n",
      "Epoch: 68, Iteration: 1/2, Loss: 4.017227889386607\n",
      "Epoch: 69, Iteration: 1/2, Loss: 4.070456462491319\n",
      "Epoch: 70, Iteration: 1/2, Loss: 3.971284883030216\n",
      "Epoch: 71, Iteration: 1/2, Loss: 3.9801227370792134\n",
      "Epoch: 72, Iteration: 1/2, Loss: 3.982273270871862\n",
      "Epoch: 73, Iteration: 1/2, Loss: 3.909000462433936\n",
      "Epoch: 74, Iteration: 1/2, Loss: 3.9260082778984264\n",
      "Epoch: 75, Iteration: 1/2, Loss: 3.8631433423823607\n",
      "Epoch: 76, Iteration: 1/2, Loss: 3.9265627185992042\n",
      "Epoch: 77, Iteration: 1/2, Loss: 3.8466007633903168\n",
      "Epoch: 78, Iteration: 1/2, Loss: 3.825788869714292\n",
      "Epoch: 79, Iteration: 1/2, Loss: 3.847106523188889\n",
      "Epoch: 80, Iteration: 1/2, Loss: 3.7685625345513403\n",
      "Epoch: 81, Iteration: 1/2, Loss: 3.720583452961404\n",
      "Epoch: 82, Iteration: 1/2, Loss: 3.704753457293518\n",
      "Epoch: 83, Iteration: 1/2, Loss: 3.616873638247251\n",
      "Epoch: 84, Iteration: 1/2, Loss: 3.6524861513138998\n",
      "Epoch: 85, Iteration: 1/2, Loss: 3.5180442792874436\n",
      "Epoch: 86, Iteration: 1/2, Loss: 3.5308913898784393\n",
      "Epoch: 87, Iteration: 1/2, Loss: 3.484728815597184\n",
      "Epoch: 88, Iteration: 1/2, Loss: 3.569486592271526\n",
      "Epoch: 89, Iteration: 1/2, Loss: 3.4324746227252936\n",
      "Epoch: 90, Iteration: 1/2, Loss: 3.294989220674831\n",
      "Epoch: 91, Iteration: 1/2, Loss: 3.206837613489217\n",
      "Epoch: 92, Iteration: 1/2, Loss: 3.2694005297964965\n",
      "Epoch: 93, Iteration: 1/2, Loss: 3.056493323651227\n",
      "Epoch: 94, Iteration: 1/2, Loss: 3.3049893678641826\n",
      "Epoch: 95, Iteration: 1/2, Loss: 3.15094774564536\n",
      "Epoch: 96, Iteration: 1/2, Loss: 3.1141223420131796\n",
      "Epoch: 97, Iteration: 1/2, Loss: 2.9329809322067026\n",
      "Epoch: 98, Iteration: 1/2, Loss: 2.846477230277719\n",
      "Epoch: 99, Iteration: 1/2, Loss: 2.732429298166772\n",
      "Epoch: 100, Iteration: 1/2, Loss: 2.9793873723112068\n",
      "Epoch: 101, Iteration: 1/2, Loss: 2.8051792281215944\n",
      "Epoch: 102, Iteration: 1/2, Loss: 2.7500722234077086\n",
      "Epoch: 103, Iteration: 1/2, Loss: 2.6550543608451553\n",
      "Epoch: 104, Iteration: 1/2, Loss: 2.6913686363635323\n",
      "Epoch: 105, Iteration: 1/2, Loss: 2.5161429734906147\n",
      "Epoch: 106, Iteration: 1/2, Loss: 2.546202936106771\n",
      "Epoch: 107, Iteration: 1/2, Loss: 2.519320459999269\n",
      "Epoch: 108, Iteration: 1/2, Loss: 2.474321070407126\n",
      "Epoch: 109, Iteration: 1/2, Loss: 2.544543523745264\n",
      "Epoch: 110, Iteration: 1/2, Loss: 2.169959936095364\n",
      "Epoch: 111, Iteration: 1/2, Loss: 2.243655928464284\n",
      "Epoch: 112, Iteration: 1/2, Loss: 2.333993914722308\n",
      "Epoch: 113, Iteration: 1/2, Loss: 2.2512392809273054\n",
      "Epoch: 114, Iteration: 1/2, Loss: 2.3397518483468307\n",
      "Epoch: 115, Iteration: 1/2, Loss: 2.018651785622671\n",
      "Epoch: 116, Iteration: 1/2, Loss: 2.265519970378552\n",
      "Epoch: 117, Iteration: 1/2, Loss: 2.067319199823856\n",
      "Epoch: 118, Iteration: 1/2, Loss: 2.0538902461297583\n",
      "Epoch: 119, Iteration: 1/2, Loss: 2.041726004537158\n",
      "Epoch: 120, Iteration: 1/2, Loss: 2.1460590705295823\n",
      "Epoch: 121, Iteration: 1/2, Loss: 1.9016967437645125\n",
      "Epoch: 122, Iteration: 1/2, Loss: 2.0515458449908204\n",
      "Epoch: 123, Iteration: 1/2, Loss: 1.861798003266638\n",
      "Epoch: 124, Iteration: 1/2, Loss: 1.9238085331723065\n",
      "Epoch: 125, Iteration: 1/2, Loss: 1.9336352795572878\n",
      "Epoch: 126, Iteration: 1/2, Loss: 1.8526652966221455\n",
      "Epoch: 127, Iteration: 1/2, Loss: 1.8812058614419886\n",
      "Epoch: 128, Iteration: 1/2, Loss: 1.7894582182995253\n",
      "Epoch: 129, Iteration: 1/2, Loss: 1.8720526597265776\n",
      "Epoch: 130, Iteration: 1/2, Loss: 1.8172388143231586\n",
      "Epoch: 131, Iteration: 1/2, Loss: 1.7445749605122054\n",
      "Epoch: 132, Iteration: 1/2, Loss: 1.7707298427938614\n",
      "Epoch: 133, Iteration: 1/2, Loss: 1.770392068890573\n",
      "Epoch: 134, Iteration: 1/2, Loss: 1.7585074962450795\n",
      "Epoch: 135, Iteration: 1/2, Loss: 1.7591230081249076\n",
      "Epoch: 136, Iteration: 1/2, Loss: 1.6778111439849481\n",
      "Epoch: 137, Iteration: 1/2, Loss: 1.7516852558602818\n",
      "Epoch: 138, Iteration: 1/2, Loss: 1.6629740945308527\n",
      "Epoch: 139, Iteration: 1/2, Loss: 1.6842663473635717\n",
      "Epoch: 140, Iteration: 1/2, Loss: 1.6771586502725966\n",
      "Epoch: 141, Iteration: 1/2, Loss: 1.6772385129596796\n",
      "Epoch: 142, Iteration: 1/2, Loss: 1.6949802830949785\n",
      "Epoch: 143, Iteration: 1/2, Loss: 1.6544164024992807\n",
      "Epoch: 144, Iteration: 1/2, Loss: 1.6267767037398628\n",
      "Epoch: 145, Iteration: 1/2, Loss: 1.6384367344886952\n",
      "Epoch: 146, Iteration: 1/2, Loss: 1.6297332236726254\n",
      "Epoch: 147, Iteration: 1/2, Loss: 1.5846630340171113\n",
      "Epoch: 148, Iteration: 1/2, Loss: 1.6161340353605809\n",
      "Epoch: 149, Iteration: 1/2, Loss: 1.6152447815370206\n",
      "Epoch: 150, Iteration: 1/2, Loss: 1.617580587589152\n",
      "Epoch: 151, Iteration: 1/2, Loss: 1.6067152876461743\n",
      "Epoch: 152, Iteration: 1/2, Loss: 1.5463945974063802\n",
      "Epoch: 153, Iteration: 1/2, Loss: 1.6112194928510932\n",
      "Epoch: 154, Iteration: 1/2, Loss: 1.5762833008966626\n",
      "Epoch: 155, Iteration: 1/2, Loss: 1.5677294421297985\n",
      "Epoch: 156, Iteration: 1/2, Loss: 1.5569630459898214\n",
      "Epoch: 157, Iteration: 1/2, Loss: 1.5496150657662184\n",
      "Epoch: 158, Iteration: 1/2, Loss: 1.5826613516679007\n",
      "Epoch: 159, Iteration: 1/2, Loss: 1.5501532011168941\n",
      "Epoch: 160, Iteration: 1/2, Loss: 1.5713360837095414\n",
      "Epoch: 161, Iteration: 1/2, Loss: 1.5136270738950846\n",
      "Epoch: 162, Iteration: 1/2, Loss: 1.5712622736086033\n",
      "Epoch: 163, Iteration: 1/2, Loss: 1.5079069978119137\n",
      "Epoch: 164, Iteration: 1/2, Loss: 1.516194088163715\n",
      "Epoch: 165, Iteration: 1/2, Loss: 1.5684193364086356\n",
      "Epoch: 166, Iteration: 1/2, Loss: 1.4975967471640703\n",
      "Epoch: 167, Iteration: 1/2, Loss: 1.5175115209836254\n",
      "Epoch: 168, Iteration: 1/2, Loss: 1.5379963043736575\n",
      "Epoch: 169, Iteration: 1/2, Loss: 1.5423472719876594\n",
      "Epoch: 170, Iteration: 1/2, Loss: 1.4812095106091858\n",
      "Epoch: 171, Iteration: 1/2, Loss: 1.5393128044032796\n",
      "Epoch: 172, Iteration: 1/2, Loss: 1.4939071001819246\n",
      "Epoch: 173, Iteration: 1/2, Loss: 1.521925362743377\n",
      "Epoch: 174, Iteration: 1/2, Loss: 1.488515760256294\n",
      "Epoch: 175, Iteration: 1/2, Loss: 1.5072852845905618\n",
      "Epoch: 176, Iteration: 1/2, Loss: 1.5095568362332574\n",
      "Epoch: 177, Iteration: 1/2, Loss: 1.48836562731824\n",
      "Epoch: 178, Iteration: 1/2, Loss: 1.4895311306427665\n",
      "Epoch: 179, Iteration: 1/2, Loss: 1.493224393347895\n",
      "Epoch: 180, Iteration: 1/2, Loss: 1.4959343396493558\n",
      "Epoch: 181, Iteration: 1/2, Loss: 1.4853378548716\n",
      "Epoch: 182, Iteration: 1/2, Loss: 1.4786162762104786\n",
      "Epoch: 183, Iteration: 1/2, Loss: 1.4815628327631587\n",
      "Epoch: 184, Iteration: 1/2, Loss: 1.4879251983480688\n",
      "Epoch: 185, Iteration: 1/2, Loss: 1.4905439364197175\n",
      "Epoch: 186, Iteration: 1/2, Loss: 1.4679537094214994\n",
      "Epoch: 187, Iteration: 1/2, Loss: 1.4897196203615215\n",
      "Epoch: 188, Iteration: 1/2, Loss: 1.4808143785219092\n",
      "Epoch: 189, Iteration: 1/2, Loss: 1.4757796270847279\n",
      "Epoch: 190, Iteration: 1/2, Loss: 1.4806364790595918\n",
      "Epoch: 191, Iteration: 1/2, Loss: 1.4649830919995313\n",
      "Epoch: 192, Iteration: 1/2, Loss: 1.4712681289655274\n",
      "Epoch: 193, Iteration: 1/2, Loss: 1.4655160023139375\n",
      "Epoch: 194, Iteration: 1/2, Loss: 1.4688234245260816\n",
      "Epoch: 195, Iteration: 1/2, Loss: 1.469769512636587\n",
      "Epoch: 196, Iteration: 1/2, Loss: 1.4659974394558404\n",
      "Epoch: 197, Iteration: 1/2, Loss: 1.4638951797704336\n",
      "Epoch: 198, Iteration: 1/2, Loss: 1.4630690931668198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████▍                                                  | 343/1000 [00:00<00:00, 1147.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199, Iteration: 1/2, Loss: 1.4592312090098218\n",
      "Epoch: 200, Iteration: 1/2, Loss: 1.4606754375684785\n",
      "Epoch: 201, Iteration: 1/2, Loss: 1.4625970012628704\n",
      "Epoch: 202, Iteration: 1/2, Loss: 1.4584397043173243\n",
      "Epoch: 203, Iteration: 1/2, Loss: 1.463629156745451\n",
      "Epoch: 204, Iteration: 1/2, Loss: 1.4559345461485307\n",
      "Epoch: 205, Iteration: 1/2, Loss: 1.447981729042557\n",
      "Epoch: 206, Iteration: 1/2, Loss: 1.453975270116426\n",
      "Epoch: 207, Iteration: 1/2, Loss: 1.4538292242904196\n",
      "Epoch: 208, Iteration: 1/2, Loss: 1.4523654529333643\n",
      "Epoch: 209, Iteration: 1/2, Loss: 1.44679509647849\n",
      "Epoch: 210, Iteration: 1/2, Loss: 1.455718756339344\n",
      "Epoch: 211, Iteration: 1/2, Loss: 1.4575394540494653\n",
      "Epoch: 212, Iteration: 1/2, Loss: 1.4345059869699717\n",
      "Epoch: 213, Iteration: 1/2, Loss: 1.450480833003505\n",
      "Epoch: 214, Iteration: 1/2, Loss: 1.4521910381892322\n",
      "Epoch: 215, Iteration: 1/2, Loss: 1.4466255162969985\n",
      "Epoch: 216, Iteration: 1/2, Loss: 1.4545935668887782\n",
      "Epoch: 217, Iteration: 1/2, Loss: 1.4299619009753726\n",
      "Epoch: 218, Iteration: 1/2, Loss: 1.44446398509092\n",
      "Epoch: 219, Iteration: 1/2, Loss: 1.4504019360382712\n",
      "Epoch: 220, Iteration: 1/2, Loss: 1.438138541866537\n",
      "Epoch: 221, Iteration: 1/2, Loss: 1.452698598162765\n",
      "Epoch: 222, Iteration: 1/2, Loss: 1.4368711260567864\n",
      "Epoch: 223, Iteration: 1/2, Loss: 1.4334414329324807\n",
      "Epoch: 224, Iteration: 1/2, Loss: 1.4416858653341493\n",
      "Epoch: 225, Iteration: 1/2, Loss: 1.449591400500208\n",
      "Epoch: 226, Iteration: 1/2, Loss: 1.4335385831344973\n",
      "Epoch: 227, Iteration: 1/2, Loss: 1.4440828584016878\n",
      "Epoch: 228, Iteration: 1/2, Loss: 1.433075555645717\n",
      "Epoch: 229, Iteration: 1/2, Loss: 1.4372076251373105\n",
      "Epoch: 230, Iteration: 1/2, Loss: 1.436687877897355\n",
      "Epoch: 231, Iteration: 1/2, Loss: 1.4345938201689554\n",
      "Epoch: 232, Iteration: 1/2, Loss: 1.4300615129160528\n",
      "Epoch: 233, Iteration: 1/2, Loss: 1.4418838262218885\n",
      "Epoch: 234, Iteration: 1/2, Loss: 1.4327022313049333\n",
      "Epoch: 235, Iteration: 1/2, Loss: 1.4349208953517678\n",
      "Epoch: 236, Iteration: 1/2, Loss: 1.4337652099109872\n",
      "Epoch: 237, Iteration: 1/2, Loss: 1.436243518184424\n",
      "Epoch: 238, Iteration: 1/2, Loss: 1.4271538832872217\n",
      "Epoch: 239, Iteration: 1/2, Loss: 1.4329378474787018\n",
      "Epoch: 240, Iteration: 1/2, Loss: 1.4268419943853008\n",
      "Epoch: 241, Iteration: 1/2, Loss: 1.4358011386758727\n",
      "Epoch: 242, Iteration: 1/2, Loss: 1.4331444312243593\n",
      "Epoch: 243, Iteration: 1/2, Loss: 1.4258736059472472\n",
      "Epoch: 244, Iteration: 1/2, Loss: 1.4260532923497804\n",
      "Epoch: 245, Iteration: 1/2, Loss: 1.4287463323040668\n",
      "Epoch: 246, Iteration: 1/2, Loss: 1.4331701371197743\n",
      "Epoch: 247, Iteration: 1/2, Loss: 1.431754847022305\n",
      "Epoch: 248, Iteration: 1/2, Loss: 1.4272646578375519\n",
      "Epoch: 249, Iteration: 1/2, Loss: 1.4247480584245675\n",
      "Epoch: 250, Iteration: 1/2, Loss: 1.4266871102499104\n",
      "Epoch: 251, Iteration: 1/2, Loss: 1.4255869425883292\n",
      "Epoch: 252, Iteration: 1/2, Loss: 1.4271061659825794\n",
      "Epoch: 253, Iteration: 1/2, Loss: 1.422184491353082\n",
      "Epoch: 254, Iteration: 1/2, Loss: 1.4283150530489066\n",
      "Epoch: 255, Iteration: 1/2, Loss: 1.4286645648475111\n",
      "Epoch: 256, Iteration: 1/2, Loss: 1.4247063822088069\n",
      "Epoch: 257, Iteration: 1/2, Loss: 1.4209136535684315\n",
      "Epoch: 258, Iteration: 1/2, Loss: 1.427435235828761\n",
      "Epoch: 259, Iteration: 1/2, Loss: 1.420203900660462\n",
      "Epoch: 260, Iteration: 1/2, Loss: 1.4241726816720193\n",
      "Epoch: 261, Iteration: 1/2, Loss: 1.4229991509898365\n",
      "Epoch: 262, Iteration: 1/2, Loss: 1.4252941787959645\n",
      "Epoch: 263, Iteration: 1/2, Loss: 1.419584007924601\n",
      "Epoch: 264, Iteration: 1/2, Loss: 1.4220246762950843\n",
      "Epoch: 265, Iteration: 1/2, Loss: 1.4175839672110295\n",
      "Epoch: 266, Iteration: 1/2, Loss: 1.4250497319533308\n",
      "Epoch: 267, Iteration: 1/2, Loss: 1.422141182333909\n",
      "Epoch: 268, Iteration: 1/2, Loss: 1.4228295503786201\n",
      "Epoch: 269, Iteration: 1/2, Loss: 1.41815839392603\n",
      "Epoch: 270, Iteration: 1/2, Loss: 1.4171127913557389\n",
      "Epoch: 271, Iteration: 1/2, Loss: 1.4224387890169243\n",
      "Epoch: 272, Iteration: 1/2, Loss: 1.4169051114374887\n",
      "Epoch: 273, Iteration: 1/2, Loss: 1.4217783815872944\n",
      "Epoch: 274, Iteration: 1/2, Loss: 1.4195803268703897\n",
      "Epoch: 275, Iteration: 1/2, Loss: 1.4226013189917237\n",
      "Epoch: 276, Iteration: 1/2, Loss: 1.4125068398648422\n",
      "Epoch: 277, Iteration: 1/2, Loss: 1.421164875879911\n",
      "Epoch: 278, Iteration: 1/2, Loss: 1.418158687524576\n",
      "Epoch: 279, Iteration: 1/2, Loss: 1.4199491853865291\n",
      "Epoch: 280, Iteration: 1/2, Loss: 1.4153173872263123\n",
      "Epoch: 281, Iteration: 1/2, Loss: 1.4199577932233938\n",
      "Epoch: 282, Iteration: 1/2, Loss: 1.4140564582535924\n",
      "Epoch: 283, Iteration: 1/2, Loss: 1.4168894525646367\n",
      "Epoch: 284, Iteration: 1/2, Loss: 1.4165248116200755\n",
      "Epoch: 285, Iteration: 1/2, Loss: 1.417241137393003\n",
      "Epoch: 286, Iteration: 1/2, Loss: 1.4161041098526812\n",
      "Epoch: 287, Iteration: 1/2, Loss: 1.4150704123663855\n",
      "Epoch: 288, Iteration: 1/2, Loss: 1.418602575256794\n",
      "Epoch: 289, Iteration: 1/2, Loss: 1.4130744199040235\n",
      "Epoch: 290, Iteration: 1/2, Loss: 1.4128091754074736\n",
      "Epoch: 291, Iteration: 1/2, Loss: 1.416641862234307\n",
      "Epoch: 292, Iteration: 1/2, Loss: 1.4132726781551574\n",
      "Epoch: 293, Iteration: 1/2, Loss: 1.414644252552781\n",
      "Epoch: 294, Iteration: 1/2, Loss: 1.4186534625978129\n",
      "Epoch: 295, Iteration: 1/2, Loss: 1.41419758795092\n",
      "Epoch: 296, Iteration: 1/2, Loss: 1.4121459969481198\n",
      "Epoch: 297, Iteration: 1/2, Loss: 1.4134449432314993\n",
      "Epoch: 298, Iteration: 1/2, Loss: 1.4139567182893247\n",
      "Epoch: 299, Iteration: 1/2, Loss: 1.415271066649037\n",
      "Epoch: 300, Iteration: 1/2, Loss: 1.4109722875178279\n",
      "Epoch: 301, Iteration: 1/2, Loss: 1.4156068251449607\n",
      "Epoch: 302, Iteration: 1/2, Loss: 1.4128384916853047\n",
      "Epoch: 303, Iteration: 1/2, Loss: 1.4104891999790499\n",
      "Epoch: 304, Iteration: 1/2, Loss: 1.4121692231343954\n",
      "Epoch: 305, Iteration: 1/2, Loss: 1.4126493067815389\n",
      "Epoch: 306, Iteration: 1/2, Loss: 1.4124577742368096\n",
      "Epoch: 307, Iteration: 1/2, Loss: 1.4133619149417496\n",
      "Epoch: 308, Iteration: 1/2, Loss: 1.4099900680421744\n",
      "Epoch: 309, Iteration: 1/2, Loss: 1.4116635199461358\n",
      "Epoch: 310, Iteration: 1/2, Loss: 1.4114358040195185\n",
      "Epoch: 311, Iteration: 1/2, Loss: 1.411268716514339\n",
      "Epoch: 312, Iteration: 1/2, Loss: 1.4087467214586307\n",
      "Epoch: 313, Iteration: 1/2, Loss: 1.4113391594046205\n",
      "Epoch: 314, Iteration: 1/2, Loss: 1.412452360746336\n",
      "Epoch: 315, Iteration: 1/2, Loss: 1.4083532450037515\n",
      "Epoch: 316, Iteration: 1/2, Loss: 1.4104914129837192\n",
      "Epoch: 317, Iteration: 1/2, Loss: 1.4131805856116635\n",
      "Epoch: 318, Iteration: 1/2, Loss: 1.4097736520905206\n",
      "Epoch: 319, Iteration: 1/2, Loss: 1.4100162999437813\n",
      "Epoch: 320, Iteration: 1/2, Loss: 1.4114767444491467\n",
      "Epoch: 321, Iteration: 1/2, Loss: 1.4078297674433145\n",
      "Epoch: 322, Iteration: 1/2, Loss: 1.4113761042697255\n",
      "Epoch: 323, Iteration: 1/2, Loss: 1.4079042381023121\n",
      "Epoch: 324, Iteration: 1/2, Loss: 1.4092288312372458\n",
      "Epoch: 325, Iteration: 1/2, Loss: 1.4088990688221092\n",
      "Epoch: 326, Iteration: 1/2, Loss: 1.4086633736695182\n",
      "Epoch: 327, Iteration: 1/2, Loss: 1.4094327105365734\n",
      "Epoch: 328, Iteration: 1/2, Loss: 1.4084700107319383\n",
      "Epoch: 329, Iteration: 1/2, Loss: 1.4088030464797194\n",
      "Epoch: 330, Iteration: 1/2, Loss: 1.4087922756592368\n",
      "Epoch: 331, Iteration: 1/2, Loss: 1.4082933309855659\n",
      "Epoch: 332, Iteration: 1/2, Loss: 1.407880363888982\n",
      "Epoch: 333, Iteration: 1/2, Loss: 1.4097888213482537\n",
      "Epoch: 334, Iteration: 1/2, Loss: 1.4075690507822074\n",
      "Epoch: 335, Iteration: 1/2, Loss: 1.405860778725818\n",
      "Epoch: 336, Iteration: 1/2, Loss: 1.4080063819109176\n",
      "Epoch: 337, Iteration: 1/2, Loss: 1.4091307677374092\n",
      "Epoch: 338, Iteration: 1/2, Loss: 1.4054969747376198\n",
      "Epoch: 339, Iteration: 1/2, Loss: 1.4075868503416216\n",
      "Epoch: 340, Iteration: 1/2, Loss: 1.4071877309191403\n",
      "Epoch: 341, Iteration: 1/2, Loss: 1.4075640294717053\n",
      "Epoch: 342, Iteration: 1/2, Loss: 1.40477261193162\n",
      "Epoch: 343, Iteration: 1/2, Loss: 1.4084853040251122\n",
      "Epoch: 344, Iteration: 1/2, Loss: 1.4048898187803374\n",
      "Epoch: 345, Iteration: 1/2, Loss: 1.4099381278184964\n",
      "Epoch: 346, Iteration: 1/2, Loss: 1.4033341628761575\n",
      "Epoch: 347, Iteration: 1/2, Loss: 1.408175669065422\n",
      "Epoch: 348, Iteration: 1/2, Loss: 1.4057743593189884\n",
      "Epoch: 349, Iteration: 1/2, Loss: 1.406911827951307\n",
      "Epoch: 350, Iteration: 1/2, Loss: 1.4070028504580108\n",
      "Epoch: 351, Iteration: 1/2, Loss: 1.4046724813242228\n",
      "Epoch: 352, Iteration: 1/2, Loss: 1.4043553056675708\n",
      "Epoch: 353, Iteration: 1/2, Loss: 1.407173946679845\n",
      "Epoch: 354, Iteration: 1/2, Loss: 1.405424231285556\n",
      "Epoch: 355, Iteration: 1/2, Loss: 1.4052203124926206\n",
      "Epoch: 356, Iteration: 1/2, Loss: 1.4075324417370125\n",
      "Epoch: 357, Iteration: 1/2, Loss: 1.4035970461393665\n",
      "Epoch: 358, Iteration: 1/2, Loss: 1.4064193765063684\n",
      "Epoch: 359, Iteration: 1/2, Loss: 1.405399446060894\n",
      "Epoch: 360, Iteration: 1/2, Loss: 1.4034827162176553\n",
      "Epoch: 361, Iteration: 1/2, Loss: 1.4035568757997083\n",
      "Epoch: 362, Iteration: 1/2, Loss: 1.407780051936826\n",
      "Epoch: 363, Iteration: 1/2, Loss: 1.402963046588405\n",
      "Epoch: 364, Iteration: 1/2, Loss: 1.4045887805435064\n",
      "Epoch: 365, Iteration: 1/2, Loss: 1.4046541195948112\n",
      "Epoch: 366, Iteration: 1/2, Loss: 1.402847623634432\n",
      "Epoch: 367, Iteration: 1/2, Loss: 1.4046379056421332\n",
      "Epoch: 368, Iteration: 1/2, Loss: 1.4055306792164997\n",
      "Epoch: 369, Iteration: 1/2, Loss: 1.4025805230796478\n",
      "Epoch: 370, Iteration: 1/2, Loss: 1.4056244713837784\n",
      "Epoch: 371, Iteration: 1/2, Loss: 1.4035526117422537\n",
      "Epoch: 372, Iteration: 1/2, Loss: 1.4030278773009208\n",
      "Epoch: 373, Iteration: 1/2, Loss: 1.4046443286430579\n",
      "Epoch: 374, Iteration: 1/2, Loss: 1.404391029060086\n",
      "Epoch: 375, Iteration: 1/2, Loss: 1.4021108011895547\n",
      "Epoch: 376, Iteration: 1/2, Loss: 1.4035607086797195\n",
      "Epoch: 377, Iteration: 1/2, Loss: 1.4034593137670448\n",
      "Epoch: 378, Iteration: 1/2, Loss: 1.4033753058846659\n",
      "Epoch: 379, Iteration: 1/2, Loss: 1.404356370705362\n",
      "Epoch: 380, Iteration: 1/2, Loss: 1.4033062006763453\n",
      "Epoch: 381, Iteration: 1/2, Loss: 1.4030078982552836\n",
      "Epoch: 382, Iteration: 1/2, Loss: 1.4016113713874172\n",
      "Epoch: 383, Iteration: 1/2, Loss: 1.4029680242920457\n",
      "Epoch: 384, Iteration: 1/2, Loss: 1.4054635335982104\n",
      "Epoch: 385, Iteration: 1/2, Loss: 1.4003365930556002\n",
      "Epoch: 386, Iteration: 1/2, Loss: 1.4037628956674673\n",
      "Epoch: 387, Iteration: 1/2, Loss: 1.4029187305184365\n",
      "Epoch: 388, Iteration: 1/2, Loss: 1.40154570362821\n",
      "Epoch: 389, Iteration: 1/2, Loss: 1.403244730488153\n",
      "Epoch: 390, Iteration: 1/2, Loss: 1.4024208529716875\n",
      "Epoch: 391, Iteration: 1/2, Loss: 1.402702921993742\n",
      "Epoch: 392, Iteration: 1/2, Loss: 1.402247819930028\n",
      "Epoch: 393, Iteration: 1/2, Loss: 1.403198376015668\n",
      "Epoch: 394, Iteration: 1/2, Loss: 1.4010361534052023\n",
      "Epoch: 395, Iteration: 1/2, Loss: 1.4023861615326052\n",
      "Epoch: 396, Iteration: 1/2, Loss: 1.4002991480886904\n",
      "Epoch: 397, Iteration: 1/2, Loss: 1.402261226038965\n",
      "Epoch: 398, Iteration: 1/2, Loss: 1.404117078950002\n",
      "Epoch: 399, Iteration: 1/2, Loss: 1.4007944348474455\n",
      "Epoch: 400, Iteration: 1/2, Loss: 1.4014411449954767\n",
      "Epoch: 401, Iteration: 1/2, Loss: 1.4012775429447526\n",
      "Epoch: 402, Iteration: 1/2, Loss: 1.4028484047771388\n",
      "Epoch: 403, Iteration: 1/2, Loss: 1.3995052217906363\n",
      "Epoch: 404, Iteration: 1/2, Loss: 1.402449334161124\n",
      "Epoch: 405, Iteration: 1/2, Loss: 1.4013545567131027\n",
      "Epoch: 406, Iteration: 1/2, Loss: 1.4012957138880497\n",
      "Epoch: 407, Iteration: 1/2, Loss: 1.4011439674516972\n",
      "Epoch: 408, Iteration: 1/2, Loss: 1.4023919465870245\n",
      "Epoch: 409, Iteration: 1/2, Loss: 1.3986864395692589\n",
      "Epoch: 410, Iteration: 1/2, Loss: 1.400961741625846\n",
      "Epoch: 411, Iteration: 1/2, Loss: 1.4022627997640613\n",
      "Epoch: 412, Iteration: 1/2, Loss: 1.4021200926127582\n",
      "Epoch: 413, Iteration: 1/2, Loss: 1.4005163186494305\n",
      "Epoch: 414, Iteration: 1/2, Loss: 1.399887486118483\n",
      "Epoch: 415, Iteration: 1/2, Loss: 1.401600588840057\n",
      "Epoch: 416, Iteration: 1/2, Loss: 1.3994560566188436\n",
      "Epoch: 417, Iteration: 1/2, Loss: 1.400827167723984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████▌                                | 579/1000 [00:00<00:00, 1161.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 418, Iteration: 1/2, Loss: 1.3994203048922271\n",
      "Epoch: 419, Iteration: 1/2, Loss: 1.4015928340424282\n",
      "Epoch: 420, Iteration: 1/2, Loss: 1.3995375468633453\n",
      "Epoch: 421, Iteration: 1/2, Loss: 1.4009874907048991\n",
      "Epoch: 422, Iteration: 1/2, Loss: 1.4008342028977574\n",
      "Epoch: 423, Iteration: 1/2, Loss: 1.4002347405270628\n",
      "Epoch: 424, Iteration: 1/2, Loss: 1.4007970546817996\n",
      "Epoch: 425, Iteration: 1/2, Loss: 1.399507566333389\n",
      "Epoch: 426, Iteration: 1/2, Loss: 1.3997692288298493\n",
      "Epoch: 427, Iteration: 1/2, Loss: 1.4000117716108322\n",
      "Epoch: 428, Iteration: 1/2, Loss: 1.4011363355684625\n",
      "Epoch: 429, Iteration: 1/2, Loss: 1.3976572495157837\n",
      "Epoch: 430, Iteration: 1/2, Loss: 1.400908910471443\n",
      "Epoch: 431, Iteration: 1/2, Loss: 1.3986773902577792\n",
      "Epoch: 432, Iteration: 1/2, Loss: 1.3997411177494579\n",
      "Epoch: 433, Iteration: 1/2, Loss: 1.401065518044351\n",
      "Epoch: 434, Iteration: 1/2, Loss: 1.399343442324968\n",
      "Epoch: 435, Iteration: 1/2, Loss: 1.4004337247644978\n",
      "Epoch: 436, Iteration: 1/2, Loss: 1.3986658317279361\n",
      "Epoch: 437, Iteration: 1/2, Loss: 1.4005957875193342\n",
      "Epoch: 438, Iteration: 1/2, Loss: 1.3982931635676392\n",
      "Epoch: 439, Iteration: 1/2, Loss: 1.3983493454979863\n",
      "Epoch: 440, Iteration: 1/2, Loss: 1.4014406202110155\n",
      "Epoch: 441, Iteration: 1/2, Loss: 1.398427456353463\n",
      "Epoch: 442, Iteration: 1/2, Loss: 1.3987211532158588\n",
      "Epoch: 443, Iteration: 1/2, Loss: 1.400208175141585\n",
      "Epoch: 444, Iteration: 1/2, Loss: 1.399377455768509\n",
      "Epoch: 445, Iteration: 1/2, Loss: 1.3987946854241589\n",
      "Epoch: 446, Iteration: 1/2, Loss: 1.399276071747878\n",
      "Epoch: 447, Iteration: 1/2, Loss: 1.397933986061469\n",
      "Epoch: 448, Iteration: 1/2, Loss: 1.3989199134200916\n",
      "Epoch: 449, Iteration: 1/2, Loss: 1.3988235906500521\n",
      "Epoch: 450, Iteration: 1/2, Loss: 1.398068882165604\n",
      "Epoch: 451, Iteration: 1/2, Loss: 1.398779739310411\n",
      "Epoch: 452, Iteration: 1/2, Loss: 1.3984763408723129\n",
      "Epoch: 453, Iteration: 1/2, Loss: 1.4007235038639734\n",
      "Epoch: 454, Iteration: 1/2, Loss: 1.3985906583124186\n",
      "Epoch: 455, Iteration: 1/2, Loss: 1.39837226421692\n",
      "Epoch: 456, Iteration: 1/2, Loss: 1.396780736715312\n",
      "Epoch: 457, Iteration: 1/2, Loss: 1.400252170196408\n",
      "Epoch: 458, Iteration: 1/2, Loss: 1.3979323344553847\n",
      "Epoch: 459, Iteration: 1/2, Loss: 1.3981956193494205\n",
      "Epoch: 460, Iteration: 1/2, Loss: 1.3981157408516776\n",
      "Epoch: 461, Iteration: 1/2, Loss: 1.3985640434205369\n",
      "Epoch: 462, Iteration: 1/2, Loss: 1.3982368442259165\n",
      "Epoch: 463, Iteration: 1/2, Loss: 1.397515513280518\n",
      "Epoch: 464, Iteration: 1/2, Loss: 1.3989019476046878\n",
      "Epoch: 465, Iteration: 1/2, Loss: 1.3991237370497267\n",
      "Epoch: 466, Iteration: 1/2, Loss: 1.3971543087968707\n",
      "Epoch: 467, Iteration: 1/2, Loss: 1.3980252126201558\n",
      "Epoch: 468, Iteration: 1/2, Loss: 1.3973160570411873\n",
      "Epoch: 469, Iteration: 1/2, Loss: 1.3989099695863307\n",
      "Epoch: 470, Iteration: 1/2, Loss: 1.3970062730956758\n",
      "Epoch: 471, Iteration: 1/2, Loss: 1.3988166491974834\n",
      "Epoch: 472, Iteration: 1/2, Loss: 1.398331418467941\n",
      "Epoch: 473, Iteration: 1/2, Loss: 1.3970942793108558\n",
      "Epoch: 474, Iteration: 1/2, Loss: 1.3986791336952864\n",
      "Epoch: 475, Iteration: 1/2, Loss: 1.3968457316788752\n",
      "Epoch: 476, Iteration: 1/2, Loss: 1.398562902628143\n",
      "Epoch: 477, Iteration: 1/2, Loss: 1.3976452962192343\n",
      "Epoch: 478, Iteration: 1/2, Loss: 1.3967111834404324\n",
      "Epoch: 479, Iteration: 1/2, Loss: 1.3977936345029707\n",
      "Epoch: 480, Iteration: 1/2, Loss: 1.396415546378138\n",
      "Epoch: 481, Iteration: 1/2, Loss: 1.3984053398073402\n",
      "Epoch: 482, Iteration: 1/2, Loss: 1.3972314497048015\n",
      "Epoch: 483, Iteration: 1/2, Loss: 1.3967319658981006\n",
      "Epoch: 484, Iteration: 1/2, Loss: 1.3991278685729696\n",
      "Epoch: 485, Iteration: 1/2, Loss: 1.3964632198164564\n",
      "Epoch: 486, Iteration: 1/2, Loss: 1.3979762605998276\n",
      "Epoch: 487, Iteration: 1/2, Loss: 1.3965912535420213\n",
      "Epoch: 488, Iteration: 1/2, Loss: 1.3972210651092825\n",
      "Epoch: 489, Iteration: 1/2, Loss: 1.397187103703064\n",
      "Epoch: 490, Iteration: 1/2, Loss: 1.3980081292995017\n",
      "Epoch: 491, Iteration: 1/2, Loss: 1.3962659972381464\n",
      "Epoch: 492, Iteration: 1/2, Loss: 1.39773473057864\n",
      "Epoch: 493, Iteration: 1/2, Loss: 1.3970366213481213\n",
      "Epoch: 494, Iteration: 1/2, Loss: 1.396361198596555\n",
      "Epoch: 495, Iteration: 1/2, Loss: 1.396967458234261\n",
      "Epoch: 496, Iteration: 1/2, Loss: 1.396961159199427\n",
      "Epoch: 497, Iteration: 1/2, Loss: 1.3960679608822275\n",
      "Epoch: 498, Iteration: 1/2, Loss: 1.397692924218046\n",
      "Epoch: 499, Iteration: 1/2, Loss: 1.3968364406828289\n",
      "Epoch: 500, Iteration: 1/2, Loss: 1.3961632313014698\n",
      "Epoch: 501, Iteration: 1/2, Loss: 1.3971892708292306\n",
      "Epoch: 502, Iteration: 1/2, Loss: 1.396930417503635\n",
      "Epoch: 503, Iteration: 1/2, Loss: 1.396075333009267\n",
      "Epoch: 504, Iteration: 1/2, Loss: 1.3972874991264665\n",
      "Epoch: 505, Iteration: 1/2, Loss: 1.3966029734146845\n",
      "Epoch: 506, Iteration: 1/2, Loss: 1.3972124627077926\n",
      "Epoch: 507, Iteration: 1/2, Loss: 1.395765118493035\n",
      "Epoch: 508, Iteration: 1/2, Loss: 1.3967297561593073\n",
      "Epoch: 509, Iteration: 1/2, Loss: 1.3964769199240747\n",
      "Epoch: 510, Iteration: 1/2, Loss: 1.3956881112866597\n",
      "Epoch: 511, Iteration: 1/2, Loss: 1.3972219990026145\n",
      "Epoch: 512, Iteration: 1/2, Loss: 1.3961987908281186\n",
      "Epoch: 513, Iteration: 1/2, Loss: 1.3973411570880374\n",
      "Epoch: 514, Iteration: 1/2, Loss: 1.3955583484014373\n",
      "Epoch: 515, Iteration: 1/2, Loss: 1.395705713598863\n",
      "Epoch: 516, Iteration: 1/2, Loss: 1.396852566564981\n",
      "Epoch: 517, Iteration: 1/2, Loss: 1.395656189393027\n",
      "Epoch: 518, Iteration: 1/2, Loss: 1.3969801153267043\n",
      "Epoch: 519, Iteration: 1/2, Loss: 1.3954188632499411\n",
      "Epoch: 520, Iteration: 1/2, Loss: 1.39730345448034\n",
      "Epoch: 521, Iteration: 1/2, Loss: 1.3955473892173946\n",
      "Epoch: 522, Iteration: 1/2, Loss: 1.395498541434667\n",
      "Epoch: 523, Iteration: 1/2, Loss: 1.3966352679629548\n",
      "Epoch: 524, Iteration: 1/2, Loss: 1.396012494937585\n",
      "Epoch: 525, Iteration: 1/2, Loss: 1.3960085749831332\n",
      "Epoch: 526, Iteration: 1/2, Loss: 1.3954029239974526\n",
      "Epoch: 527, Iteration: 1/2, Loss: 1.3957518515652407\n",
      "Epoch: 528, Iteration: 1/2, Loss: 1.3966439643770634\n",
      "Epoch: 529, Iteration: 1/2, Loss: 1.3958971049904287\n",
      "Epoch: 530, Iteration: 1/2, Loss: 1.3958382538138814\n",
      "Epoch: 531, Iteration: 1/2, Loss: 1.3963717556011834\n",
      "Epoch: 532, Iteration: 1/2, Loss: 1.3959646793289116\n",
      "Epoch: 533, Iteration: 1/2, Loss: 1.3955871187691589\n",
      "Epoch: 534, Iteration: 1/2, Loss: 1.3944728072248187\n",
      "Epoch: 535, Iteration: 1/2, Loss: 1.3958814775033073\n",
      "Epoch: 536, Iteration: 1/2, Loss: 1.3956729334054094\n",
      "Epoch: 537, Iteration: 1/2, Loss: 1.3967355328622006\n",
      "Epoch: 538, Iteration: 1/2, Loss: 1.3950853088486777\n",
      "Epoch: 539, Iteration: 1/2, Loss: 1.396137647277457\n",
      "Epoch: 540, Iteration: 1/2, Loss: 1.3950261440717195\n",
      "Epoch: 541, Iteration: 1/2, Loss: 1.395709275271399\n",
      "Epoch: 542, Iteration: 1/2, Loss: 1.3955119376671958\n",
      "Epoch: 543, Iteration: 1/2, Loss: 1.3958410792173281\n",
      "Epoch: 544, Iteration: 1/2, Loss: 1.3949335343518252\n",
      "Epoch: 545, Iteration: 1/2, Loss: 1.3954314853568286\n",
      "Epoch: 546, Iteration: 1/2, Loss: 1.3952381370251952\n",
      "Epoch: 547, Iteration: 1/2, Loss: 1.3962317937115423\n",
      "Epoch: 548, Iteration: 1/2, Loss: 1.3953578441847447\n",
      "Epoch: 549, Iteration: 1/2, Loss: 1.3946366952957296\n",
      "Epoch: 550, Iteration: 1/2, Loss: 1.3952909041493404\n",
      "Epoch: 551, Iteration: 1/2, Loss: 1.394761554954953\n",
      "Epoch: 552, Iteration: 1/2, Loss: 1.3957760126843017\n",
      "Epoch: 553, Iteration: 1/2, Loss: 1.395216912054111\n",
      "Epoch: 554, Iteration: 1/2, Loss: 1.3958722921861253\n",
      "Epoch: 555, Iteration: 1/2, Loss: 1.3938281851933731\n",
      "Epoch: 556, Iteration: 1/2, Loss: 1.3958130539086668\n",
      "Epoch: 557, Iteration: 1/2, Loss: 1.3952855501993708\n",
      "Epoch: 558, Iteration: 1/2, Loss: 1.3949277131559374\n",
      "Epoch: 559, Iteration: 1/2, Loss: 1.3945733728391139\n",
      "Epoch: 560, Iteration: 1/2, Loss: 1.394895858454379\n",
      "Epoch: 561, Iteration: 1/2, Loss: 1.3956725575672508\n",
      "Epoch: 562, Iteration: 1/2, Loss: 1.395504265191429\n",
      "Epoch: 563, Iteration: 1/2, Loss: 1.3944766157073667\n",
      "Epoch: 564, Iteration: 1/2, Loss: 1.394459527162057\n",
      "Epoch: 565, Iteration: 1/2, Loss: 1.3960603354797954\n",
      "Epoch: 566, Iteration: 1/2, Loss: 1.3947488115894242\n",
      "Epoch: 567, Iteration: 1/2, Loss: 1.3943775085174517\n",
      "Epoch: 568, Iteration: 1/2, Loss: 1.394866415907236\n",
      "Epoch: 569, Iteration: 1/2, Loss: 1.3954656599969901\n",
      "Epoch: 570, Iteration: 1/2, Loss: 1.394801867415497\n",
      "Epoch: 571, Iteration: 1/2, Loss: 1.393511535967317\n",
      "Epoch: 572, Iteration: 1/2, Loss: 1.3954012654456043\n",
      "Epoch: 573, Iteration: 1/2, Loss: 1.3952121621784228\n",
      "Epoch: 574, Iteration: 1/2, Loss: 1.3948605200179567\n",
      "Epoch: 575, Iteration: 1/2, Loss: 1.3935823297205951\n",
      "Epoch: 576, Iteration: 1/2, Loss: 1.3956265322175683\n",
      "Epoch: 577, Iteration: 1/2, Loss: 1.3941634602931776\n",
      "Epoch: 578, Iteration: 1/2, Loss: 1.3941615152694153\n",
      "Epoch: 579, Iteration: 1/2, Loss: 1.3950602831230872\n",
      "Epoch: 580, Iteration: 1/2, Loss: 1.3952009145672148\n",
      "Epoch: 581, Iteration: 1/2, Loss: 1.394089531088517\n",
      "Epoch: 582, Iteration: 1/2, Loss: 1.3939237593701637\n",
      "Epoch: 583, Iteration: 1/2, Loss: 1.394976870040724\n",
      "Epoch: 584, Iteration: 1/2, Loss: 1.394938572859636\n",
      "Epoch: 585, Iteration: 1/2, Loss: 1.3935587165734904\n",
      "Epoch: 586, Iteration: 1/2, Loss: 1.3950491668297549\n",
      "Epoch: 587, Iteration: 1/2, Loss: 1.3942822453297832\n",
      "Epoch: 588, Iteration: 1/2, Loss: 1.3948566939521179\n",
      "Epoch: 589, Iteration: 1/2, Loss: 1.3939274878448262\n",
      "Epoch: 590, Iteration: 1/2, Loss: 1.3943499177785286\n",
      "Epoch: 591, Iteration: 1/2, Loss: 1.394940951632631\n",
      "Epoch: 592, Iteration: 1/2, Loss: 1.3943165981977206\n",
      "Epoch: 593, Iteration: 1/2, Loss: 1.393708079835323\n",
      "Epoch: 594, Iteration: 1/2, Loss: 1.3936792696324072\n",
      "Epoch: 595, Iteration: 1/2, Loss: 1.3952865373149979\n",
      "Epoch: 596, Iteration: 1/2, Loss: 1.3937900439024098\n",
      "Epoch: 597, Iteration: 1/2, Loss: 1.3942150080169462\n",
      "Epoch: 598, Iteration: 1/2, Loss: 1.39375234244465\n",
      "Epoch: 599, Iteration: 1/2, Loss: 1.3946155903954063\n",
      "Epoch: 600, Iteration: 1/2, Loss: 1.3941633697630422\n",
      "Epoch: 601, Iteration: 1/2, Loss: 1.3936964132220755\n",
      "Epoch: 602, Iteration: 1/2, Loss: 1.3946861736308904\n",
      "Epoch: 603, Iteration: 1/2, Loss: 1.3939577468385238\n",
      "Epoch: 604, Iteration: 1/2, Loss: 1.3940737293086827\n",
      "Epoch: 605, Iteration: 1/2, Loss: 1.394186875466016\n",
      "Epoch: 606, Iteration: 1/2, Loss: 1.3933215762642683\n",
      "Epoch: 607, Iteration: 1/2, Loss: 1.3951542342586762\n",
      "Epoch: 608, Iteration: 1/2, Loss: 1.3939930258691562\n",
      "Epoch: 609, Iteration: 1/2, Loss: 1.393827756253201\n",
      "Epoch: 610, Iteration: 1/2, Loss: 1.393105150304241\n",
      "Epoch: 611, Iteration: 1/2, Loss: 1.3949299793975383\n",
      "Epoch: 612, Iteration: 1/2, Loss: 1.3939157511787323\n",
      "Epoch: 613, Iteration: 1/2, Loss: 1.3933299489082835\n",
      "Epoch: 614, Iteration: 1/2, Loss: 1.3938898643734294\n",
      "Epoch: 615, Iteration: 1/2, Loss: 1.393849340155402\n",
      "Epoch: 616, Iteration: 1/2, Loss: 1.3944003027467229\n",
      "Epoch: 617, Iteration: 1/2, Loss: 1.3932746627136958\n",
      "Epoch: 618, Iteration: 1/2, Loss: 1.3933796603697308\n",
      "Epoch: 619, Iteration: 1/2, Loss: 1.3942101571002068\n",
      "Epoch: 620, Iteration: 1/2, Loss: 1.3943070088622544\n",
      "Epoch: 621, Iteration: 1/2, Loss: 1.3926565669590838\n",
      "Epoch: 622, Iteration: 1/2, Loss: 1.394411293305252\n",
      "Epoch: 623, Iteration: 1/2, Loss: 1.3935850839535937\n",
      "Epoch: 624, Iteration: 1/2, Loss: 1.3936935982819438\n",
      "Epoch: 625, Iteration: 1/2, Loss: 1.3938005123700352\n",
      "Epoch: 626, Iteration: 1/2, Loss: 1.3935209465163838\n",
      "Epoch: 627, Iteration: 1/2, Loss: 1.393774886466085\n",
      "Epoch: 628, Iteration: 1/2, Loss: 1.3934868231700093\n",
      "Epoch: 629, Iteration: 1/2, Loss: 1.3932004027570646\n",
      "Epoch: 630, Iteration: 1/2, Loss: 1.3940015896203204\n",
      "Epoch: 631, Iteration: 1/2, Loss: 1.3935582298037028\n",
      "Epoch: 632, Iteration: 1/2, Loss: 1.3936854054265062\n",
      "Epoch: 633, Iteration: 1/2, Loss: 1.3934107962205584\n",
      "Epoch: 634, Iteration: 1/2, Loss: 1.3933794932939096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████▌              | 813/1000 [00:00<00:00, 1159.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 635, Iteration: 1/2, Loss: 1.3936258203117082\n",
      "Epoch: 636, Iteration: 1/2, Loss: 1.3929603642563326\n",
      "Epoch: 637, Iteration: 1/2, Loss: 1.3934665032253304\n",
      "Epoch: 638, Iteration: 1/2, Loss: 1.3943563196347073\n",
      "Epoch: 639, Iteration: 1/2, Loss: 1.3930434486573406\n",
      "Epoch: 640, Iteration: 1/2, Loss: 1.3930222735978905\n",
      "Epoch: 641, Iteration: 1/2, Loss: 1.3938009814867827\n",
      "Epoch: 642, Iteration: 1/2, Loss: 1.3933747642199892\n",
      "Epoch: 643, Iteration: 1/2, Loss: 1.3929683111089972\n",
      "Epoch: 644, Iteration: 1/2, Loss: 1.3938647676740654\n",
      "Epoch: 645, Iteration: 1/2, Loss: 1.3932079823571848\n",
      "Epoch: 646, Iteration: 1/2, Loss: 1.39293396516516\n",
      "Epoch: 647, Iteration: 1/2, Loss: 1.3936715350458861\n",
      "Epoch: 648, Iteration: 1/2, Loss: 1.393658242914547\n",
      "Epoch: 649, Iteration: 1/2, Loss: 1.3928942829550341\n",
      "Epoch: 650, Iteration: 1/2, Loss: 1.3927409259213315\n",
      "Epoch: 651, Iteration: 1/2, Loss: 1.3933671717560014\n",
      "Epoch: 652, Iteration: 1/2, Loss: 1.3935854472022244\n",
      "Epoch: 653, Iteration: 1/2, Loss: 1.3932065471766364\n",
      "Epoch: 654, Iteration: 1/2, Loss: 1.3931722375955438\n",
      "Epoch: 655, Iteration: 1/2, Loss: 1.3936766908315934\n",
      "Epoch: 656, Iteration: 1/2, Loss: 1.3931522074554794\n",
      "Epoch: 657, Iteration: 1/2, Loss: 1.3931364033804647\n",
      "Epoch: 658, Iteration: 1/2, Loss: 1.3926353365239188\n",
      "Epoch: 659, Iteration: 1/2, Loss: 1.3931060637394457\n",
      "Epoch: 660, Iteration: 1/2, Loss: 1.39320148440925\n",
      "Epoch: 661, Iteration: 1/2, Loss: 1.3924702661992336\n",
      "Epoch: 662, Iteration: 1/2, Loss: 1.3931724648201675\n",
      "Epoch: 663, Iteration: 1/2, Loss: 1.3930459536071642\n",
      "Epoch: 664, Iteration: 1/2, Loss: 1.392920201185248\n",
      "Epoch: 665, Iteration: 1/2, Loss: 1.3934920384816947\n",
      "Epoch: 666, Iteration: 1/2, Loss: 1.3928815351685526\n",
      "Epoch: 667, Iteration: 1/2, Loss: 1.3932221962890514\n",
      "Epoch: 668, Iteration: 1/2, Loss: 1.392847509692412\n",
      "Epoch: 669, Iteration: 1/2, Loss: 1.3924752092611103\n",
      "Epoch: 670, Iteration: 1/2, Loss: 1.393417278758021\n",
      "Epoch: 671, Iteration: 1/2, Loss: 1.3930439851196108\n",
      "Epoch: 672, Iteration: 1/2, Loss: 1.3927818027415433\n",
      "Epoch: 673, Iteration: 1/2, Loss: 1.3932655151699955\n",
      "Epoch: 674, Iteration: 1/2, Loss: 1.3924024318642274\n",
      "Epoch: 675, Iteration: 1/2, Loss: 1.3929727494748123\n",
      "Epoch: 676, Iteration: 1/2, Loss: 1.393325819985534\n",
      "Epoch: 677, Iteration: 1/2, Loss: 1.3923699184507194\n",
      "Epoch: 678, Iteration: 1/2, Loss: 1.3928261052286544\n",
      "Epoch: 679, Iteration: 1/2, Loss: 1.3931490723843765\n",
      "Epoch: 680, Iteration: 1/2, Loss: 1.3921082935886258\n",
      "Epoch: 681, Iteration: 1/2, Loss: 1.3932368869821876\n",
      "Epoch: 682, Iteration: 1/2, Loss: 1.3926480163701318\n",
      "Epoch: 683, Iteration: 1/2, Loss: 1.3927504585003692\n",
      "Epoch: 684, Iteration: 1/2, Loss: 1.3930771564517612\n",
      "Epoch: 685, Iteration: 1/2, Loss: 1.3919312804425539\n",
      "Epoch: 686, Iteration: 1/2, Loss: 1.3932761945060177\n",
      "Epoch: 687, Iteration: 1/2, Loss: 1.3925919470409187\n",
      "Epoch: 688, Iteration: 1/2, Loss: 1.3930062015058717\n",
      "Epoch: 689, Iteration: 1/2, Loss: 1.3923312810458215\n",
      "Epoch: 690, Iteration: 1/2, Loss: 1.3927683034781826\n",
      "Epoch: 691, Iteration: 1/2, Loss: 1.3926391255637236\n",
      "Epoch: 692, Iteration: 1/2, Loss: 1.3921829951200722\n",
      "Epoch: 693, Iteration: 1/2, Loss: 1.3930563619455287\n",
      "Epoch: 694, Iteration: 1/2, Loss: 1.3921456609584961\n",
      "Epoch: 695, Iteration: 1/2, Loss: 1.3925871132172236\n",
      "Epoch: 696, Iteration: 1/2, Loss: 1.3932543752179494\n",
      "Epoch: 697, Iteration: 1/2, Loss: 1.392208328879173\n",
      "Epoch: 698, Iteration: 1/2, Loss: 1.3925548143150666\n",
      "Epoch: 699, Iteration: 1/2, Loss: 1.3922087233534608\n",
      "Epoch: 700, Iteration: 1/2, Loss: 1.3931698548064029\n",
      "Epoch: 701, Iteration: 1/2, Loss: 1.392617392947625\n",
      "Epoch: 702, Iteration: 1/2, Loss: 1.3920600841713717\n",
      "Epoch: 703, Iteration: 1/2, Loss: 1.3929197228342711\n",
      "Epoch: 704, Iteration: 1/2, Loss: 1.3919165194046046\n",
      "Epoch: 705, Iteration: 1/2, Loss: 1.3926712831850838\n",
      "Epoch: 706, Iteration: 1/2, Loss: 1.3926652197056093\n",
      "Epoch: 707, Iteration: 1/2, Loss: 1.3922044922110448\n",
      "Epoch: 708, Iteration: 1/2, Loss: 1.3923059538410527\n",
      "Epoch: 709, Iteration: 1/2, Loss: 1.3924028155144696\n",
      "Epoch: 710, Iteration: 1/2, Loss: 1.3923903167844383\n",
      "Epoch: 711, Iteration: 1/2, Loss: 1.3923675800142719\n",
      "Epoch: 712, Iteration: 1/2, Loss: 1.3928087322849971\n",
      "Epoch: 713, Iteration: 1/2, Loss: 1.392026776778712\n",
      "Epoch: 714, Iteration: 1/2, Loss: 1.3922441966561956\n",
      "Epoch: 715, Iteration: 1/2, Loss: 1.3918861986381437\n",
      "Epoch: 716, Iteration: 1/2, Loss: 1.3924206110374826\n",
      "Epoch: 717, Iteration: 1/2, Loss: 1.3922092835501279\n",
      "Epoch: 718, Iteration: 1/2, Loss: 1.3930310191509525\n",
      "Epoch: 719, Iteration: 1/2, Loss: 1.3915302831081382\n",
      "Epoch: 720, Iteration: 1/2, Loss: 1.3927030305632768\n",
      "Epoch: 721, Iteration: 1/2, Loss: 1.3921371870634414\n",
      "Epoch: 722, Iteration: 1/2, Loss: 1.392242215067324\n",
      "Epoch: 723, Iteration: 1/2, Loss: 1.392335363353412\n",
      "Epoch: 724, Iteration: 1/2, Loss: 1.3921113051286722\n",
      "Epoch: 725, Iteration: 1/2, Loss: 1.3923083461322046\n",
      "Epoch: 726, Iteration: 1/2, Loss: 1.3924986549242249\n",
      "Epoch: 727, Iteration: 1/2, Loss: 1.3918891829024942\n",
      "Epoch: 728, Iteration: 1/2, Loss: 1.3918437376734343\n",
      "Epoch: 729, Iteration: 1/2, Loss: 1.3924745059402555\n",
      "Epoch: 730, Iteration: 1/2, Loss: 1.39214394481344\n",
      "Epoch: 731, Iteration: 1/2, Loss: 1.3917317656838706\n",
      "Epoch: 732, Iteration: 1/2, Loss: 1.3925384180370455\n",
      "Epoch: 733, Iteration: 1/2, Loss: 1.3925010174241101\n",
      "Epoch: 734, Iteration: 1/2, Loss: 1.3916994110563237\n",
      "Epoch: 735, Iteration: 1/2, Loss: 1.3919848994103385\n",
      "Epoch: 736, Iteration: 1/2, Loss: 1.3922792100477646\n",
      "Epoch: 737, Iteration: 1/2, Loss: 1.3915654802176194\n",
      "Epoch: 738, Iteration: 1/2, Loss: 1.3924507817700356\n",
      "Epoch: 739, Iteration: 1/2, Loss: 1.392449631228798\n",
      "Epoch: 740, Iteration: 1/2, Loss: 1.3916358151929407\n",
      "Epoch: 741, Iteration: 1/2, Loss: 1.3917025384567916\n",
      "Epoch: 742, Iteration: 1/2, Loss: 1.3927181686939931\n",
      "Epoch: 743, Iteration: 1/2, Loss: 1.3914937945724317\n",
      "Epoch: 744, Iteration: 1/2, Loss: 1.3920969612832979\n",
      "Epoch: 745, Iteration: 1/2, Loss: 1.391975418388169\n",
      "Epoch: 746, Iteration: 1/2, Loss: 1.3923409531081967\n",
      "Epoch: 747, Iteration: 1/2, Loss: 1.3911745493300298\n",
      "Epoch: 748, Iteration: 1/2, Loss: 1.3923295136059488\n",
      "Epoch: 749, Iteration: 1/2, Loss: 1.391533771355915\n",
      "Epoch: 750, Iteration: 1/2, Loss: 1.391931378374498\n",
      "Epoch: 751, Iteration: 1/2, Loss: 1.3923067419936748\n",
      "Epoch: 752, Iteration: 1/2, Loss: 1.3915016408091323\n",
      "Epoch: 753, Iteration: 1/2, Loss: 1.3921739255273402\n",
      "Epoch: 754, Iteration: 1/2, Loss: 1.3919728791188108\n",
      "Epoch: 755, Iteration: 1/2, Loss: 1.3915828025934058\n",
      "Epoch: 756, Iteration: 1/2, Loss: 1.3922355979185748\n",
      "Epoch: 757, Iteration: 1/2, Loss: 1.3917457575141903\n",
      "Epoch: 758, Iteration: 1/2, Loss: 1.3918225740981134\n",
      "Epoch: 759, Iteration: 1/2, Loss: 1.3914459127982437\n",
      "Epoch: 760, Iteration: 1/2, Loss: 1.3922128780516878\n",
      "Epoch: 761, Iteration: 1/2, Loss: 1.3917892763820028\n",
      "Epoch: 762, Iteration: 1/2, Loss: 1.392083521067458\n",
      "Epoch: 763, Iteration: 1/2, Loss: 1.3911041741012293\n",
      "Epoch: 764, Iteration: 1/2, Loss: 1.3921438675870672\n",
      "Epoch: 765, Iteration: 1/2, Loss: 1.391771059998161\n",
      "Epoch: 766, Iteration: 1/2, Loss: 1.3917625200265824\n",
      "Epoch: 767, Iteration: 1/2, Loss: 1.3917261417892182\n",
      "Epoch: 768, Iteration: 1/2, Loss: 1.3920999083404837\n",
      "Epoch: 769, Iteration: 1/2, Loss: 1.3909685067472037\n",
      "Epoch: 770, Iteration: 1/2, Loss: 1.3924578499886284\n",
      "Epoch: 771, Iteration: 1/2, Loss: 1.3913184481529721\n",
      "Epoch: 772, Iteration: 1/2, Loss: 1.3919856931929102\n",
      "Epoch: 773, Iteration: 1/2, Loss: 1.391108800586354\n",
      "Epoch: 774, Iteration: 1/2, Loss: 1.3920463377045855\n",
      "Epoch: 775, Iteration: 1/2, Loss: 1.3916582517832372\n",
      "Epoch: 776, Iteration: 1/2, Loss: 1.391648512749776\n",
      "Epoch: 777, Iteration: 1/2, Loss: 1.3912759084421065\n",
      "Epoch: 778, Iteration: 1/2, Loss: 1.3921795576980118\n",
      "Epoch: 779, Iteration: 1/2, Loss: 1.390964777801776\n",
      "Epoch: 780, Iteration: 1/2, Loss: 1.3919819067314905\n",
      "Epoch: 781, Iteration: 1/2, Loss: 1.391957865911256\n",
      "Epoch: 782, Iteration: 1/2, Loss: 1.3908709763861602\n",
      "Epoch: 783, Iteration: 1/2, Loss: 1.3920299573608133\n",
      "Epoch: 784, Iteration: 1/2, Loss: 1.3913862829015753\n",
      "Epoch: 785, Iteration: 1/2, Loss: 1.3916391211140815\n",
      "Epoch: 786, Iteration: 1/2, Loss: 1.3915744990579229\n",
      "Epoch: 787, Iteration: 1/2, Loss: 1.3912655597571606\n",
      "Epoch: 788, Iteration: 1/2, Loss: 1.3920574781525414\n",
      "Epoch: 789, Iteration: 1/2, Loss: 1.3911687047528516\n",
      "Epoch: 790, Iteration: 1/2, Loss: 1.3916145611484518\n",
      "Epoch: 791, Iteration: 1/2, Loss: 1.3914899345603313\n",
      "Epoch: 792, Iteration: 1/2, Loss: 1.3917539283465012\n",
      "Epoch: 793, Iteration: 1/2, Loss: 1.3915854758963153\n",
      "Epoch: 794, Iteration: 1/2, Loss: 1.390763180845151\n",
      "Epoch: 795, Iteration: 1/2, Loss: 1.391725305235728\n",
      "Epoch: 796, Iteration: 1/2, Loss: 1.391532634303104\n",
      "Epoch: 797, Iteration: 1/2, Loss: 1.3914593732564013\n",
      "Epoch: 798, Iteration: 1/2, Loss: 1.3914484951963386\n",
      "Epoch: 799, Iteration: 1/2, Loss: 1.3914273121790381\n",
      "Epoch: 800, Iteration: 1/2, Loss: 1.391137833753624\n",
      "Epoch: 801, Iteration: 1/2, Loss: 1.3915903618117604\n",
      "Epoch: 802, Iteration: 1/2, Loss: 1.391489098317819\n",
      "Epoch: 803, Iteration: 1/2, Loss: 1.3911359752388521\n",
      "Epoch: 804, Iteration: 1/2, Loss: 1.3917240708969072\n",
      "Epoch: 805, Iteration: 1/2, Loss: 1.3912849453168747\n",
      "Epoch: 806, Iteration: 1/2, Loss: 1.391364649602144\n",
      "Epoch: 807, Iteration: 1/2, Loss: 1.3913671757504156\n",
      "Epoch: 808, Iteration: 1/2, Loss: 1.3910689985812255\n",
      "Epoch: 809, Iteration: 1/2, Loss: 1.3913507898275483\n",
      "Epoch: 810, Iteration: 1/2, Loss: 1.3914928385445493\n",
      "Epoch: 811, Iteration: 1/2, Loss: 1.3913196431407608\n",
      "Epoch: 812, Iteration: 1/2, Loss: 1.3911474542724283\n",
      "Epoch: 813, Iteration: 1/2, Loss: 1.3916371944759023\n",
      "Epoch: 814, Iteration: 1/2, Loss: 1.3911943437447305\n",
      "Epoch: 815, Iteration: 1/2, Loss: 1.391309138143053\n",
      "Epoch: 816, Iteration: 1/2, Loss: 1.391607946946677\n",
      "Epoch: 817, Iteration: 1/2, Loss: 1.3908357855335436\n",
      "Epoch: 818, Iteration: 1/2, Loss: 1.3913440559426893\n",
      "Epoch: 819, Iteration: 1/2, Loss: 1.3912608169768257\n",
      "Epoch: 820, Iteration: 1/2, Loss: 1.3912287832047077\n",
      "Epoch: 821, Iteration: 1/2, Loss: 1.391316709912925\n",
      "Epoch: 822, Iteration: 1/2, Loss: 1.3910537337949704\n",
      "Epoch: 823, Iteration: 1/2, Loss: 1.3915561557278413\n",
      "Epoch: 824, Iteration: 1/2, Loss: 1.3910346756836895\n",
      "Epoch: 825, Iteration: 1/2, Loss: 1.3911258708184935\n",
      "Epoch: 826, Iteration: 1/2, Loss: 1.3911777942570038\n",
      "Epoch: 827, Iteration: 1/2, Loss: 1.3911679324949855\n",
      "Epoch: 828, Iteration: 1/2, Loss: 1.3908602245776192\n",
      "Epoch: 829, Iteration: 1/2, Loss: 1.3914898948884207\n",
      "Epoch: 830, Iteration: 1/2, Loss: 1.391238693984544\n",
      "Epoch: 831, Iteration: 1/2, Loss: 1.3910645300920579\n",
      "Epoch: 832, Iteration: 1/2, Loss: 1.390816286737884\n",
      "Epoch: 833, Iteration: 1/2, Loss: 1.3915361715591161\n",
      "Epoch: 834, Iteration: 1/2, Loss: 1.3908022358880714\n",
      "Epoch: 835, Iteration: 1/2, Loss: 1.3911153840821409\n",
      "Epoch: 836, Iteration: 1/2, Loss: 1.3913568504666805\n",
      "Epoch: 837, Iteration: 1/2, Loss: 1.3910858294400978\n",
      "Epoch: 838, Iteration: 1/2, Loss: 1.3907587172952753\n",
      "Epoch: 839, Iteration: 1/2, Loss: 1.3914944607491502\n",
      "Epoch: 840, Iteration: 1/2, Loss: 1.3909794841363674\n",
      "Epoch: 841, Iteration: 1/2, Loss: 1.3908438040625113\n",
      "Epoch: 842, Iteration: 1/2, Loss: 1.3913742182493838\n",
      "Epoch: 843, Iteration: 1/2, Loss: 1.3909680261694106\n",
      "Epoch: 844, Iteration: 1/2, Loss: 1.3910294485327162\n",
      "Epoch: 845, Iteration: 1/2, Loss: 1.391045989479292\n",
      "Epoch: 846, Iteration: 1/2, Loss: 1.391026313959342\n",
      "Epoch: 847, Iteration: 1/2, Loss: 1.39093676160595\n",
      "Epoch: 848, Iteration: 1/2, Loss: 1.3910103583180433\n",
      "Epoch: 849, Iteration: 1/2, Loss: 1.3913939354510636\n",
      "Epoch: 850, Iteration: 1/2, Loss: 1.3906028026995467\n",
      "Epoch: 851, Iteration: 1/2, Loss: 1.3910792390443114\n",
      "Epoch: 852, Iteration: 1/2, Loss: 1.3912087222332385\n",
      "Epoch: 853, Iteration: 1/2, Loss: 1.3910503251567539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1154.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 854, Iteration: 1/2, Loss: 1.390562360651544\n",
      "Epoch: 855, Iteration: 1/2, Loss: 1.3910221903351478\n",
      "Epoch: 856, Iteration: 1/2, Loss: 1.3909479489246315\n",
      "Epoch: 857, Iteration: 1/2, Loss: 1.3911799907392286\n",
      "Epoch: 858, Iteration: 1/2, Loss: 1.3910238879377377\n",
      "Epoch: 859, Iteration: 1/2, Loss: 1.3906192716620858\n",
      "Epoch: 860, Iteration: 1/2, Loss: 1.3909043473497182\n",
      "Epoch: 861, Iteration: 1/2, Loss: 1.3909098520061076\n",
      "Epoch: 862, Iteration: 1/2, Loss: 1.3908229414994233\n",
      "Epoch: 863, Iteration: 1/2, Loss: 1.390972801078443\n",
      "Epoch: 864, Iteration: 1/2, Loss: 1.3908872585864478\n",
      "Epoch: 865, Iteration: 1/2, Loss: 1.3905773669964328\n",
      "Epoch: 866, Iteration: 1/2, Loss: 1.391251515794751\n",
      "Epoch: 867, Iteration: 1/2, Loss: 1.391009607888198\n",
      "Epoch: 868, Iteration: 1/2, Loss: 1.3903998178935515\n",
      "Epoch: 869, Iteration: 1/2, Loss: 1.3908631597180228\n",
      "Epoch: 870, Iteration: 1/2, Loss: 1.3913632176371507\n",
      "Epoch: 871, Iteration: 1/2, Loss: 1.3907573930554076\n",
      "Epoch: 872, Iteration: 1/2, Loss: 1.3906839037520902\n",
      "Epoch: 873, Iteration: 1/2, Loss: 1.3907310311026393\n",
      "Epoch: 874, Iteration: 1/2, Loss: 1.390902646697977\n",
      "Epoch: 875, Iteration: 1/2, Loss: 1.3910373728410845\n",
      "Epoch: 876, Iteration: 1/2, Loss: 1.3904900807556992\n",
      "Epoch: 877, Iteration: 1/2, Loss: 1.3905602524594567\n",
      "Epoch: 878, Iteration: 1/2, Loss: 1.3910281829338094\n",
      "Epoch: 879, Iteration: 1/2, Loss: 1.3908400413438649\n",
      "Epoch: 880, Iteration: 1/2, Loss: 1.3906939574767279\n",
      "Epoch: 881, Iteration: 1/2, Loss: 1.3909920073097553\n",
      "Epoch: 882, Iteration: 1/2, Loss: 1.3907554099510497\n",
      "Epoch: 883, Iteration: 1/2, Loss: 1.3905197303964005\n",
      "Epoch: 884, Iteration: 1/2, Loss: 1.3907537917381458\n",
      "Epoch: 885, Iteration: 1/2, Loss: 1.390418414608238\n",
      "Epoch: 886, Iteration: 1/2, Loss: 1.3908156271788772\n",
      "Epoch: 887, Iteration: 1/2, Loss: 1.3906459396284099\n",
      "Epoch: 888, Iteration: 1/2, Loss: 1.3910773985757154\n",
      "Epoch: 889, Iteration: 1/2, Loss: 1.390706134505259\n",
      "Epoch: 890, Iteration: 1/2, Loss: 1.3909246334208039\n",
      "Epoch: 891, Iteration: 1/2, Loss: 1.3901796754646467\n",
      "Epoch: 892, Iteration: 1/2, Loss: 1.3906861222703641\n",
      "Epoch: 893, Iteration: 1/2, Loss: 1.3908783624748253\n",
      "Epoch: 894, Iteration: 1/2, Loss: 1.390610223307891\n",
      "Epoch: 895, Iteration: 1/2, Loss: 1.3905153546028408\n",
      "Epoch: 896, Iteration: 1/2, Loss: 1.3908818983760391\n",
      "Epoch: 897, Iteration: 1/2, Loss: 1.3907246099280521\n",
      "Epoch: 898, Iteration: 1/2, Loss: 1.3905578571562287\n",
      "Epoch: 899, Iteration: 1/2, Loss: 1.390354892952994\n",
      "Epoch: 900, Iteration: 1/2, Loss: 1.3907173083063813\n",
      "Epoch: 901, Iteration: 1/2, Loss: 1.3908460522732837\n",
      "Epoch: 902, Iteration: 1/2, Loss: 1.3903234674801261\n",
      "Epoch: 903, Iteration: 1/2, Loss: 1.3911123640876724\n",
      "Epoch: 904, Iteration: 1/2, Loss: 1.3901637296966503\n",
      "Epoch: 905, Iteration: 1/2, Loss: 1.3908901331633539\n",
      "Epoch: 906, Iteration: 1/2, Loss: 1.3905183421142628\n",
      "Epoch: 907, Iteration: 1/2, Loss: 1.390583971364665\n",
      "Epoch: 908, Iteration: 1/2, Loss: 1.3906494981558741\n",
      "Epoch: 909, Iteration: 1/2, Loss: 1.3904860963244992\n",
      "Epoch: 910, Iteration: 1/2, Loss: 1.3903593202694444\n",
      "Epoch: 911, Iteration: 1/2, Loss: 1.3907883999492552\n",
      "Epoch: 912, Iteration: 1/2, Loss: 1.3908272318319377\n",
      "Epoch: 913, Iteration: 1/2, Loss: 1.3899805640302056\n",
      "Epoch: 914, Iteration: 1/2, Loss: 1.390597708553317\n",
      "Epoch: 915, Iteration: 1/2, Loss: 1.3910226876320135\n",
      "Epoch: 916, Iteration: 1/2, Loss: 1.39025100645955\n",
      "Epoch: 917, Iteration: 1/2, Loss: 1.3903036763137977\n",
      "Epoch: 918, Iteration: 1/2, Loss: 1.3910134274222201\n",
      "Epoch: 919, Iteration: 1/2, Loss: 1.3902912807047394\n",
      "Epoch: 920, Iteration: 1/2, Loss: 1.390416373885766\n",
      "Epoch: 921, Iteration: 1/2, Loss: 1.3907903787677482\n",
      "Epoch: 922, Iteration: 1/2, Loss: 1.3902734282389528\n",
      "Epoch: 923, Iteration: 1/2, Loss: 1.3906102705383616\n",
      "Epoch: 924, Iteration: 1/2, Loss: 1.3900618645572629\n",
      "Epoch: 925, Iteration: 1/2, Loss: 1.3906807316051921\n",
      "Epoch: 926, Iteration: 1/2, Loss: 1.3904490744139788\n",
      "Epoch: 927, Iteration: 1/2, Loss: 1.3905382376707025\n",
      "Epoch: 928, Iteration: 1/2, Loss: 1.3906601120965383\n",
      "Epoch: 929, Iteration: 1/2, Loss: 1.3902321042676182\n",
      "Epoch: 930, Iteration: 1/2, Loss: 1.3906342611889961\n",
      "Epoch: 931, Iteration: 1/2, Loss: 1.3901637541598015\n",
      "Epoch: 932, Iteration: 1/2, Loss: 1.390354829794151\n",
      "Epoch: 933, Iteration: 1/2, Loss: 1.3902785691435735\n",
      "Epoch: 934, Iteration: 1/2, Loss: 1.3906213904786344\n",
      "Epoch: 935, Iteration: 1/2, Loss: 1.3904189408331753\n",
      "Epoch: 936, Iteration: 1/2, Loss: 1.39045618540542\n",
      "Epoch: 937, Iteration: 1/2, Loss: 1.3903251770205833\n",
      "Epoch: 938, Iteration: 1/2, Loss: 1.3904001105714352\n",
      "Epoch: 939, Iteration: 1/2, Loss: 1.3903567045938365\n",
      "Epoch: 940, Iteration: 1/2, Loss: 1.3904568482465915\n",
      "Epoch: 941, Iteration: 1/2, Loss: 1.3900264455639473\n",
      "Epoch: 942, Iteration: 1/2, Loss: 1.390364259797067\n",
      "Epoch: 943, Iteration: 1/2, Loss: 1.3909058895488995\n",
      "Epoch: 944, Iteration: 1/2, Loss: 1.3900100147627936\n",
      "Epoch: 945, Iteration: 1/2, Loss: 1.3906740252814422\n",
      "Epoch: 946, Iteration: 1/2, Loss: 1.3903395902191131\n",
      "Epoch: 947, Iteration: 1/2, Loss: 1.390006682917221\n",
      "Epoch: 948, Iteration: 1/2, Loss: 1.3903959167529236\n",
      "Epoch: 949, Iteration: 1/2, Loss: 1.3901182787063604\n",
      "Epoch: 950, Iteration: 1/2, Loss: 1.390316815739006\n",
      "Epoch: 951, Iteration: 1/2, Loss: 1.3903109485674365\n",
      "Epoch: 952, Iteration: 1/2, Loss: 1.390440647544477\n",
      "Epoch: 953, Iteration: 1/2, Loss: 1.3903658994945283\n",
      "Epoch: 954, Iteration: 1/2, Loss: 1.3902801794799136\n",
      "Epoch: 955, Iteration: 1/2, Loss: 1.3904889532792926\n",
      "Epoch: 956, Iteration: 1/2, Loss: 1.389903552557027\n",
      "Epoch: 957, Iteration: 1/2, Loss: 1.3905310962757467\n",
      "Epoch: 958, Iteration: 1/2, Loss: 1.3901910146560486\n",
      "Epoch: 959, Iteration: 1/2, Loss: 1.3900765421648382\n",
      "Epoch: 960, Iteration: 1/2, Loss: 1.3904712258409067\n",
      "Epoch: 961, Iteration: 1/2, Loss: 1.3904399314201314\n",
      "Epoch: 962, Iteration: 1/2, Loss: 1.3900478798386975\n",
      "Epoch: 963, Iteration: 1/2, Loss: 1.3904400514271102\n",
      "Epoch: 964, Iteration: 1/2, Loss: 1.3902355899592707\n",
      "Epoch: 965, Iteration: 1/2, Loss: 1.3902299222573737\n",
      "Epoch: 966, Iteration: 1/2, Loss: 1.3902771625708974\n",
      "Epoch: 967, Iteration: 1/2, Loss: 1.3901533153830297\n",
      "Epoch: 968, Iteration: 1/2, Loss: 1.3897652089234245\n",
      "Epoch: 969, Iteration: 1/2, Loss: 1.3904580372565976\n",
      "Epoch: 970, Iteration: 1/2, Loss: 1.3902797794219222\n",
      "Epoch: 971, Iteration: 1/2, Loss: 1.3899349833277135\n",
      "Epoch: 972, Iteration: 1/2, Loss: 1.3903877028254137\n",
      "Epoch: 973, Iteration: 1/2, Loss: 1.3904331281705091\n",
      "Epoch: 974, Iteration: 1/2, Loss: 1.3899323290443149\n",
      "Epoch: 975, Iteration: 1/2, Loss: 1.3901615767786866\n",
      "Epoch: 976, Iteration: 1/2, Loss: 1.3902458486462963\n",
      "Epoch: 977, Iteration: 1/2, Loss: 1.3899047040947679\n",
      "Epoch: 978, Iteration: 1/2, Loss: 1.3902882567767127\n",
      "Epoch: 979, Iteration: 1/2, Loss: 1.3902044051182063\n",
      "Epoch: 980, Iteration: 1/2, Loss: 1.3901471729549197\n",
      "Epoch: 981, Iteration: 1/2, Loss: 1.3900903879165367\n",
      "Epoch: 982, Iteration: 1/2, Loss: 1.3901365825864582\n",
      "Epoch: 983, Iteration: 1/2, Loss: 1.3904386334594832\n",
      "Epoch: 984, Iteration: 1/2, Loss: 1.3900741904743144\n",
      "Epoch: 985, Iteration: 1/2, Loss: 1.38999172040567\n",
      "Epoch: 986, Iteration: 1/2, Loss: 1.3903066590007045\n",
      "Epoch: 987, Iteration: 1/2, Loss: 1.389841782663488\n",
      "Epoch: 988, Iteration: 1/2, Loss: 1.3901169209496236\n",
      "Epoch: 989, Iteration: 1/2, Loss: 1.3898572138753722\n",
      "Epoch: 990, Iteration: 1/2, Loss: 1.3903354620335504\n",
      "Epoch: 991, Iteration: 1/2, Loss: 1.3899102529842011\n",
      "Epoch: 992, Iteration: 1/2, Loss: 1.3905141294140235\n",
      "Epoch: 993, Iteration: 1/2, Loss: 1.3895725820855032\n",
      "Epoch: 994, Iteration: 1/2, Loss: 1.3905773583275591\n",
      "Epoch: 995, Iteration: 1/2, Loss: 1.3895763836594675\n",
      "Epoch: 996, Iteration: 1/2, Loss: 1.3903638235123976\n",
      "Epoch: 997, Iteration: 1/2, Loss: 1.389982291049686\n",
      "Epoch: 998, Iteration: 1/2, Loss: 1.3900768132362347\n",
      "Epoch: 999, Iteration: 1/2, Loss: 1.3897969856481607\n",
      "Epoch: 1000, Iteration: 1/2, Loss: 1.3905162273303475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "# configurations\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "# define model\n",
    "skip_gram = SkipGram(len(word2idx), hidden_size, window_size)\n",
    "sgd_optimizer = SGD()\n",
    "trainer = Trainer(skip_gram, sgd_optimizer)\n",
    "\n",
    "# start training\n",
    "trainer.fit(contexts, targets, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studying [ 2.3076906   0.790949   -1.01499     0.78101444  0.8062162 ]\n",
      "natural [-1.1617371 -2.2114336  1.0420225  1.3365339 -0.7364704]\n",
      ". [-0.02836574  0.00716158  0.02342706  0.00366387  0.01242384]\n",
      "now [-1.4463122   1.0570209   0.9299893  -1.988174   -0.09864694]\n",
      "am [ 0.6009513  -0.03649484  1.2671524   0.8690332  -2.3610373 ]\n",
      "language [ 1.1078458   1.5574567  -0.7132943  -2.11905     0.82170826]\n",
      "i [-0.01361924  0.0080411   0.00972695 -0.0208737   0.01263655]\n",
      "processing [-1.3577284 -1.5144658 -1.1657577  0.6523272  1.4017758]\n"
     ]
    }
   ],
   "source": [
    "# check skip-gram results\n",
    "wordvec = skip_gram.word_vecs\n",
    "\n",
    "for word, idx in word2idx.items():\n",
    "    print(word, wordvec[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
