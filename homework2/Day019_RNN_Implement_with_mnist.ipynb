{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkLuF_EEzVDo"
   },
   "source": [
    "# 作業: 使用 RNN 實作手寫數字辨識\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEldrrEjaDCf"
   },
   "source": [
    "##[作業目標]\n",
    "\n",
    "*   使用 Pytorch 的 RNN\n",
    "*   熟練建構 RNN 網路\n",
    "*   RNN 也可以用在簡單的影像識別應用，準確度高達 90% 以上\n",
    "\n",
    "###[動手做]\n",
    "*   在 ImageRNN 類別裡面完成 RNN 物件 basic_rnn 的建立\n",
    "*   在 ImageRNN 類別裡面完成 全連結層 FC 物件的建立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndbIZ3oNZ6bm"
   },
   "source": [
    "##[作業重點]\n",
    "\n",
    "順利實作出手寫數字辨識的 RNN 模型\n",
    "*   使用 torchvision 提供的手寫數字資料集\n",
    "*   架構 ImageRNN 類別\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVEEwALKbfM2"
   },
   "source": [
    "### 載入會使用到的套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GPtvdk2sP4WK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0NkZDsUbmiI"
   },
   "source": [
    "### 定義超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "trwbbieHQAr4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 超參數 Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 28          # rnn time step / image height\n",
    "INPUT_SIZE = 28         # rnn input size / image width\n",
    "LR = 0.01               # learning rate\n",
    "DOWNLOAD_MNIST = False   # set to True if haven't download the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGZ7Si6DbyR8"
   },
   "source": [
    "### 載入訓練資料\n",
    "建立 train_loader 物件用來載入訓練資料\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "N3oC7tiVQF2U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:64: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\brian\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:54: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 載入手寫數字資料集 Mnist digital dataset\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                         # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,            # download it if you don't have it\n",
    ")\n",
    "\n",
    "# plot one example\n",
    "print(train_data.train_data.size())     # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())   # (60000)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0KgwUnocNu4"
   },
   "source": [
    "### 載入測試資料\n",
    "建立 test_loader 物件用來載入測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EAQuTAbBQK7s"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:69: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\brian\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:59: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "test_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())\n",
    "test_x = test_data.test_data.type(torch.FloatTensor)[:2000]/255.   # shape (2000, 28, 28) value in range(0,1)\n",
    "test_y = test_data.test_labels.numpy()[:2000]    # covert to numpy array\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m68zUGTKcU7T"
   },
   "source": [
    "### 把資料顯示出來看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UtvfRBaxUuO8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import cv2\n",
    "import numpy as np\n",
    "# # Exploring the dataset\n",
    "\n",
    "# # functions to show an image\n",
    "# def imshow(img):\n",
    "#     #img = img / 2 + 0.5     # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# # get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "images = images.numpy()\n",
    "images.shape\n",
    "# cv2.imshow('myimage', np.transpose(images[0], (1,2,0)))\n",
    "# # show images\n",
    "# imshow(utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAWQFrC9ceTY"
   },
   "source": [
    "### 根據資料集的特性，定義資料參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B4TXaaeXVRnz"
   },
   "outputs": [],
   "source": [
    "# parameters \n",
    "N_STEPS = 28\n",
    "N_INPUTS = 28\n",
    "N_NEURONS = 150\n",
    "N_OUTPUTS = 10\n",
    "N_EPHOCS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt5eLAeJcmc6"
   },
   "source": [
    "### 架構 RNN 網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BbuK5nonQRcf"
   },
   "outputs": [],
   "source": [
    "class ImageRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(ImageRNN, self).__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        # 作業: 請查看 pytorch 文件，選用最基本的 RNN 來當作模型\n",
    "        self.basic_rnn = nn.RNN(n_inputs, n_neurons, 1)\n",
    "        \n",
    "        # 作業: 定義一個全連結層\n",
    "        self.FC = nn.Linear(n_neurons, n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X): \n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        X = X.permute(1, 0, 2) \n",
    "        \n",
    "        self.batch_size = X.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        out = self.FC(self.hidden.view(-1, self.n_neurons))\n",
    "        \n",
    "        return out.view(-1, self.n_outputs) # batch_size X n_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSzy_B0Rcsuw"
   },
   "source": [
    "### 實作訓練程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Qn1qmIPnVodn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Loss: 0.7186 | Train Accuracy: 76.34\n",
      "Epoch:  1 | Loss: 0.3258 | Train Accuracy: 90.34\n",
      "Epoch:  2 | Loss: 0.2396 | Train Accuracy: 93.15\n",
      "Epoch:  3 | Loss: 0.1997 | Train Accuracy: 94.32\n",
      "Epoch:  4 | Loss: 0.1729 | Train Accuracy: 95.11\n",
      "Epoch:  5 | Loss: 0.1523 | Train Accuracy: 95.75\n",
      "Epoch:  6 | Loss: 0.1464 | Train Accuracy: 95.86\n",
      "Epoch:  7 | Loss: 0.1298 | Train Accuracy: 96.36\n",
      "Epoch:  8 | Loss: 0.1252 | Train Accuracy: 96.47\n",
      "Epoch:  9 | Loss: 0.1226 | Train Accuracy: 96.55\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# use gpu if cuda is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model instance\n",
    "model = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()\n",
    "\n",
    "for epoch in range(N_EPHOCS):  # loop over the dataset multiple times\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    # TRAINING ROUND\n",
    "    for i, data in enumerate(train_loader):\n",
    "         # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden() \n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 28,28)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "         \n",
    "    model.eval()\n",
    "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f' \n",
    "          %(epoch, train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9VDiFNnczfS"
   },
   "source": [
    "### 實作測試程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0YxsptGQV51o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.51\n"
     ]
    }
   ],
   "source": [
    "# Calculate test accuracy\n",
    "test_acc = 0.0\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 28, 28)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "        \n",
    "print('Test Accuracy: %.2f'%( test_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPpqw1rDyvNYZXPTtvVfvRt",
   "collapsed_sections": [],
   "name": "作業_RNN_MNIST.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
