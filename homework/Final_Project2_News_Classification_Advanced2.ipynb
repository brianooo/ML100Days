{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U pip\n",
    "# !pip install -q numpy\n",
    "# !pip install -q pandas\n",
    "# !pip install -q ckiptagger\n",
    "# !pip install -q tqdm\n",
    "# !pip install -q tensorflow==1.14.0\n",
    "# !pip install -q ipywidgets\n",
    "# !pip install -q matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ckiptagger import WS, POS\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('news_clustering_train.tsv', sep='\\t')\n",
    "df_test = pd.read_csv('news_clustering_test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_titles = {row['index']: row['title'] for _, row in df_train.iterrows()}\n",
    "train_classes = {row['index']: row['class'] for _, row in df_train.iterrows()}\n",
    "\n",
    "test_titles = {row['index']: row['title'] for _, row in df_test.iterrows()}\n",
    "test_classes = {row['index']: row['class'] for _, row in df_test.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_news_class = ['體育', '財經', '科技', '旅遊', '農業', '遊戲']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 斷詞 + POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ws = WS('./data/')\n",
    "pos = POS('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09355e3ef9944a9592dc7be31976e038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_title_cuts = {}\n",
    "for index, title in tqdm(train_titles.items()):\n",
    "    word_s = ws([title])\n",
    "    word_p = pos(word_s)\n",
    "    train_title_cuts[index] = list(zip(word_s[0], word_p[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b47fc15f81b43b49cd279b493a6db2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_title_cuts = {}\n",
    "for index, title in tqdm(test_titles.items()):\n",
    "    word_s = ws([title])\n",
    "    word_p = pos(word_s)\n",
    "    test_title_cuts[index] = list(zip(word_s[0], word_p[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 尋找降維的詞向量：PPMI + SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "index2word = {}\n",
    "n = 0\n",
    "for index in train_title_cuts:\n",
    "    for word, flag in train_title_cuts[index]:\n",
    "        if word in word2index:\n",
    "            continue\n",
    "        word2index[word] = n \n",
    "        index2word[n] = word\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6690"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用one-hot就需要這麼大的維度的詞向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立Co-Matrix\n",
    "\n",
    "vocab_size = len(word2index)\n",
    "co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "window_size = 2\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for index in train_title_cuts:\n",
    "    for i in range(len(train_title_cuts[index])-window_size):\n",
    "        word = train_title_cuts[index][i][0]\n",
    "        word_next = [ train_title_cuts[index][i+j+1][0] for j in range(window_size)]\n",
    "        for w in word_next:\n",
    "            co_matrix[word2index[word], word2index[w]] += 1\n",
    "            co_matrix[word2index[w], word2index[word]] += 1\n",
    "\n",
    "\n",
    "# END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 1, ..., 0, 0, 0],\n",
       "       [2, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, ..., 0, 0, 0],\n",
       "       [2, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6690, 6690)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 建立PPMI\n",
    "\n",
    "def get_ppmi(co_matrix: np.ndarray, eps: float=1e-8):\n",
    "    # YOUR CODE HERE\n",
    "    N = np.sum(co_matrix)\n",
    "    S = np.sum(co_matrix, axis=0)\n",
    "    M = np.zeros(shape=co_matrix.shape)\n",
    "    for row in range(co_matrix.shape[0]):\n",
    "        for column in range(co_matrix.shape[1]):\n",
    "            pmi = np.log2(co_matrix[row, column]*N/(S[row]*S[column])+eps)\n",
    "            M[row, column] = max(0, pmi)\n",
    "\n",
    "    # END YOUR CODE\n",
    "    return M\n",
    "\n",
    "ppmi = get_ppmi(co_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  8.49278787,  9.39967847, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 8.49278787,  0.        , 10.49278787, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 9.39967847, 10.49278787,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  9.267157,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 9.267157,  0.      , 11.515084, ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.      , 11.515084,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       ...,\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ppmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce dimension to 1000 and explained variance =  0.6211811379502958\n",
      "Reduce dimension to 2000 and explained variance =  0.8167061772367108\n",
      "Reduce dimension to 3000 and explained variance =  0.9176758858740324\n"
     ]
    }
   ],
   "source": [
    "# 進行SVD分解，並得到降維的詞向量\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 使用`TruncatedSVD`進行降維，降維到dim=1000\n",
    "# YOUR CODE HERE\n",
    "\n",
    "svd1 = TruncatedSVD(n_components=1000)\n",
    "word_vectors1 = svd1.fit_transform(ppmi)\n",
    "svd2 = TruncatedSVD(n_components=2000)\n",
    "word_vectors2 = svd2.fit_transform(ppmi)\n",
    "svd3 = TruncatedSVD(n_components=3000)\n",
    "word_vectors3 = svd3.fit_transform(ppmi)\n",
    "print('Reduce dimension to 1000 and explained variance = ', svd1.explained_variance_ratio_.sum())\n",
    "print('Reduce dimension to 2000 and explained variance = ', svd2.explained_variance_ratio_.sum())\n",
    "print('Reduce dimension to 3000 and explained variance = ', svd3.explained_variance_ratio_.sum())\n",
    "\n",
    "# END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6690, 3000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = word_vectors3\n",
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新的詞向量 + Group mean vector: 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_flags = [\n",
    "    'Nh', 'Nep', 'Nes', 'DE', 'T', 'P', 'V_2', 'SHI',\n",
    "    'Dfa', 'Dfb', 'Da', 'Di', 'Dk',\n",
    "    'Caa', 'Cab', 'Cba', 'Cbb',\n",
    "    'COLONCATEGORY', 'COMMACATEGORY', 'DASHCATEGORY', 'DOTCATEGORY', 'ETCCATEGORY', 'EXCLAMATIONCATEGORY',\n",
    "    'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'PERIODCATEGORY', 'QUESTIONCATEGORY', 'SEMICOLONCATEGORY',\n",
    "    'SPCHANGECATEGORY', 'WHITESPACE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_svd_vectors = {}\n",
    "for index, pairs in train_title_cuts.items():\n",
    "    selected_word_vectors = []\n",
    "    for word, flag in pairs:\n",
    "        if word in word2index and flag not in excluded_flags:\n",
    "            selected_word_vectors.append(word_vectors[word2index[word], :])\n",
    "    vector = np.sum(selected_word_vectors, axis=0)\n",
    "    if np.sum(np.square(vector)) == 0:\n",
    "        continue\n",
    "    train_svd_vectors[index] = vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_svd_vectors = {}\n",
    "for index, pairs in test_title_cuts.items():\n",
    "    selected_word_vectors = []\n",
    "    for word, flag in pairs:\n",
    "        if word in word2index and flag not in excluded_flags:\n",
    "            selected_word_vectors.append(word_vectors[word2index[word], :])\n",
    "    vector = np.sum(selected_word_vectors, axis=0)\n",
    "    if np.sum(np.square(vector)) == 0:\n",
    "        continue\n",
    "    test_svd_vectors[index] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_vectors = {news_class: [] for news_class in all_news_class}\n",
    "for index, vector in sorted(train_svd_vectors.items()):\n",
    "    news_class = train_classes[index]\n",
    "    group_vectors[news_class].append(vector)\n",
    "\n",
    "group_mean_vector = {}\n",
    "for news_class, vectors in group_vectors.items():\n",
    "    group_mean_vector[news_class] = np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(bow1, bow2):\n",
    "    len_bow1 = np.sqrt(np.sum(np.square(bow1)))\n",
    "    len_bow2 = np.sqrt(np.sum(np.square(bow2)))\n",
    "    return np.sum(bow1 * bow2) / (len_bow1 * len_bow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = {news_class: [] for news_class in all_news_class}\n",
    "for index, vector in sorted(test_svd_vectors.items()):\n",
    "    if np.sum(np.square(vector)) == 0:\n",
    "        continue\n",
    "\n",
    "    max_val = -2.0\n",
    "    max_class = None\n",
    "    for news_class, ref_vector in group_mean_vector.items():\n",
    "        val = cosine_similarity(ref_vector, vector)\n",
    "        if val > max_val:\n",
    "            max_class = news_class\n",
    "            max_val = val\n",
    "\n",
    "    classification[max_class].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict 體育 :  Counter({'體育': 65, '遊戲': 9, '財經': 8, '旅遊': 5, '科技': 4, '農業': 4})\n",
      "predict 財經 :  Counter({'財經': 64, '科技': 22, '農業': 15, '體育': 7, '旅遊': 6, '遊戲': 6})\n",
      "predict 科技 :  Counter({'科技': 56, '體育': 15, '財經': 13, '遊戲': 8, '農業': 7, '旅遊': 6})\n",
      "predict 旅遊 :  Counter({'旅遊': 62, '農業': 10, '財經': 6, '科技': 6, '遊戲': 5, '體育': 2})\n",
      "predict 農業 :  Counter({'農業': 61, '旅遊': 9, '體育': 3, '科技': 3, '遊戲': 3, '財經': 2})\n",
      "predict 遊戲 :  Counter({'遊戲': 69, '旅遊': 10, '科技': 8, '財經': 7, '體育': 6, '農業': 2})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for group, ids in classification.items():\n",
    "    counter = Counter([test_classes[id] for id in ids])\n",
    "    print('predict', group, ': ', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict 體育 :  Counter({'體育': 61, '遊戲': 10, '旅遊': 9, '財經': 8, '科技': 5, '農業': 4})\n",
      "predict 財經 :  Counter({'財經': 62, '科技': 25, '農業': 16, '體育': 8, '遊戲': 8, '旅遊': 7})\n",
      "predict 科技 :  Counter({'科技': 51, '體育': 15, '財經': 14, '農業': 9, '遊戲': 9, '旅遊': 8})\n",
      "predict 旅遊 :  Counter({'旅遊': 58, '農業': 11, '科技': 5, '財經': 4, '體育': 2, '遊戲': 2})\n",
      "predict 農業 :  Counter({'農業': 58, '旅遊': 7, '體育': 4, '財經': 4, '遊戲': 4, '科技': 2})\n",
      "predict 遊戲 :  Counter({'遊戲': 67, '科技': 11, '旅遊': 9, '體育': 8, '財經': 8, '農業': 1})\n"
     ]
    }
   ],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# for group, ids in classification.items():\n",
    "#     counter = Counter([test_classes[id] for id in ids])\n",
    "#     print('predict', group, ': ', counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
