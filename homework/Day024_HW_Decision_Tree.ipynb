{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的:了解決策樹的節點分支依據\n",
    "本次作業可參考簡報中的延伸閱讀[訊息增益](https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-5%E8%AC%9B-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-%E4%BB%A5%E5%8F%8A%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-%E4%BB%8B%E7%B4%B9-7079b0ddfbda)部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "若你是決策樹，下列兩種分類狀況(a,b)，你會選擇哪種做分類？為什麼？\n",
    "\n",
    "<img src='img/hw_1.png' style='width:500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "計算 Information Gain by Entropy:\n",
    "\n",
    "Entropy(a)\n",
    "\n",
    "    I = -(0.5*log0.5 + 0.5*log0.5) = 1\n",
    "\n",
    "    I_left = -(0.75*log0.75+0.25*log0.25) = 0.81\n",
    "    \n",
    "    I_right = -(0.25*log0.25+0.75*log0.75) = 0.81\n",
    "    \n",
    "    IG = I-0.5*I_left-0.5*I_right = 0.19\n",
    "\n",
    "Entropy(b)\n",
    "\n",
    "    I = -(0.5*log0.5 + 0.5*log0.5) = 1\n",
    "    \n",
    "    I_left = -((3/7)*log(3/7)+(4/7)*log(4/7)) = 0.68\n",
    "    \n",
    "    I_right = -(1*log1) = 0\n",
    "    \n",
    "    IG = I - (7/8)*0.68 - (1/8)*0 = 0.41\n",
    "    \n",
    "計算 Information Gain by Gini:\n",
    "\n",
    "Gini(a)\n",
    "\n",
    "    I = 1 - (0.5**2 + 0.5**2) = 0.5\n",
    "    \n",
    "    I_left = 1 - (0.75**2 + 0.25**2) = 0.375\n",
    "    \n",
    "    I_right = 1 - (0.25**2 + 0.75**2) = 0.375\n",
    "    \n",
    "    IG = 0.5 - 0.5*0.375 - 0.5*0.375 = 0.125\n",
    "    \n",
    "Gini(b)\n",
    "\n",
    "    I = 1 - (0.5**2 + 0.5**2) = 0.5\n",
    "    \n",
    "    I_left = 1 - ((3/7)**2 + (4/7)**2) =0.49\n",
    "    \n",
    "    I_right = 1 - (1**2 + 0**2) = 0\n",
    "    \n",
    "    IG = 0.5 - (7/8)*0.49 - (1/8)*0 = 0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據 Entropy 選擇 IG 較大的 (b), 根據 Gini 選擇 IG 較大的 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 閱讀作業\n",
    "\n",
    "決策樹根據計算分割準則的不同(ex: Entropy, Gini, Gain ratio)，可分為ID3, C4.5, CART樹的算法，請同學閱讀下列文章，來更加了解決策樹的算法。\n",
    "\n",
    "[決策樹(ID3, C4.5, CART)](https://blog.csdn.net/u010089444/article/details/53241218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
